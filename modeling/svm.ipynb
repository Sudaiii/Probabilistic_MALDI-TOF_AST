{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/castudil/bacteria-multi-label/blob/main/multilabel_bac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKUeIuZcpHUl"
   },
   "source": [
    "Libraries used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "bzVprbfpWSLa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import (f1_score, multilabel_confusion_matrix,\n",
    "                             accuracy_score, hamming_loss, jaccard_score, make_scorer)\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "nQsWnulDWdDD",
    "outputId": "6f97687c-b560-4e34-fd8b-9c3ef7aeb0c7",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>...</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>Oxacillin</th>\n",
       "      <th>Clindamycin</th>\n",
       "      <th>Fusidic acid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018721</td>\n",
       "      <td>0.016147</td>\n",
       "      <td>0.016983</td>\n",
       "      <td>0.021218</td>\n",
       "      <td>0.020846</td>\n",
       "      <td>0.019784</td>\n",
       "      <td>0.019405</td>\n",
       "      <td>0.023356</td>\n",
       "      <td>0.026224</td>\n",
       "      <td>0.026569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037966</td>\n",
       "      <td>0.030364</td>\n",
       "      <td>0.037545</td>\n",
       "      <td>0.040851</td>\n",
       "      <td>0.034176</td>\n",
       "      <td>0.046110</td>\n",
       "      <td>0.025638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.009539</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>0.008314</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.008923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014496</td>\n",
       "      <td>0.024966</td>\n",
       "      <td>0.027437</td>\n",
       "      <td>0.026541</td>\n",
       "      <td>0.022940</td>\n",
       "      <td>0.020572</td>\n",
       "      <td>0.032504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022354</td>\n",
       "      <td>0.020220</td>\n",
       "      <td>0.020910</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.021436</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>0.020229</td>\n",
       "      <td>0.018818</td>\n",
       "      <td>0.018637</td>\n",
       "      <td>0.018815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024620</td>\n",
       "      <td>0.022942</td>\n",
       "      <td>0.026715</td>\n",
       "      <td>0.032045</td>\n",
       "      <td>0.030431</td>\n",
       "      <td>0.029085</td>\n",
       "      <td>0.013117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017619</td>\n",
       "      <td>0.016073</td>\n",
       "      <td>0.016407</td>\n",
       "      <td>0.018011</td>\n",
       "      <td>0.019364</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.017607</td>\n",
       "      <td>0.019116</td>\n",
       "      <td>0.023623</td>\n",
       "      <td>0.024492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051312</td>\n",
       "      <td>0.047458</td>\n",
       "      <td>0.049338</td>\n",
       "      <td>0.055039</td>\n",
       "      <td>0.054541</td>\n",
       "      <td>0.058643</td>\n",
       "      <td>0.058919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>0.006753</td>\n",
       "      <td>0.006657</td>\n",
       "      <td>0.010107</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>0.008134</td>\n",
       "      <td>0.006513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236769</td>\n",
       "      <td>0.217499</td>\n",
       "      <td>0.187244</td>\n",
       "      <td>0.216243</td>\n",
       "      <td>0.221910</td>\n",
       "      <td>0.226531</td>\n",
       "      <td>0.221965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>0.056616</td>\n",
       "      <td>0.039011</td>\n",
       "      <td>0.040380</td>\n",
       "      <td>0.048517</td>\n",
       "      <td>0.050865</td>\n",
       "      <td>0.047771</td>\n",
       "      <td>0.049312</td>\n",
       "      <td>0.048257</td>\n",
       "      <td>0.049417</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021169</td>\n",
       "      <td>0.023617</td>\n",
       "      <td>0.033694</td>\n",
       "      <td>0.021037</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>0.125837</td>\n",
       "      <td>0.107712</td>\n",
       "      <td>0.109186</td>\n",
       "      <td>0.107613</td>\n",
       "      <td>0.109855</td>\n",
       "      <td>0.105060</td>\n",
       "      <td>0.099640</td>\n",
       "      <td>0.104169</td>\n",
       "      <td>0.120303</td>\n",
       "      <td>0.125067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082375</td>\n",
       "      <td>0.083446</td>\n",
       "      <td>0.096510</td>\n",
       "      <td>0.084883</td>\n",
       "      <td>0.092228</td>\n",
       "      <td>0.085599</td>\n",
       "      <td>0.042142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035603</td>\n",
       "      <td>0.039994</td>\n",
       "      <td>0.042372</td>\n",
       "      <td>0.046666</td>\n",
       "      <td>0.045781</td>\n",
       "      <td>0.043914</td>\n",
       "      <td>0.039875</td>\n",
       "      <td>0.037170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006903</td>\n",
       "      <td>0.008322</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>0.005443</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.005588</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>0.004853</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049241</td>\n",
       "      <td>0.039586</td>\n",
       "      <td>0.050542</td>\n",
       "      <td>0.039139</td>\n",
       "      <td>0.046816</td>\n",
       "      <td>0.043036</td>\n",
       "      <td>0.037402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>0.026184</td>\n",
       "      <td>0.022810</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.020464</td>\n",
       "      <td>0.026694</td>\n",
       "      <td>0.024624</td>\n",
       "      <td>0.025140</td>\n",
       "      <td>0.026609</td>\n",
       "      <td>0.024203</td>\n",
       "      <td>0.020953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090198</td>\n",
       "      <td>0.101889</td>\n",
       "      <td>0.105174</td>\n",
       "      <td>0.122065</td>\n",
       "      <td>0.095740</td>\n",
       "      <td>0.082289</td>\n",
       "      <td>0.081714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2824 rows × 8003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          2000      2001      2002      2003      2004      2005      2006   \n",
       "0     0.018721  0.016147  0.016983  0.021218  0.020846  0.019784  0.019405  \\\n",
       "1     0.009001  0.007475  0.006874  0.008575  0.009539  0.007894  0.008314   \n",
       "2     0.022354  0.020220  0.020910  0.024631  0.021436  0.021197  0.020229   \n",
       "3     0.017619  0.016073  0.016407  0.018011  0.019364  0.018950  0.017607   \n",
       "4     0.008264  0.008229  0.006753  0.006657  0.010107  0.007039  0.008250   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2819  0.056616  0.039011  0.040380  0.048517  0.050865  0.047771  0.049312   \n",
       "2820  0.125837  0.107712  0.109186  0.107613  0.109855  0.105060  0.099640   \n",
       "2821  0.000000  0.000000  0.035603  0.039994  0.042372  0.046666  0.045781   \n",
       "2822  0.005443  0.005998  0.003670  0.005588  0.006124  0.005019  0.004853   \n",
       "2823  0.026184  0.022810  0.023200  0.020464  0.026694  0.024624  0.025140   \n",
       "\n",
       "          2007      2008      2009  ...      9993      9994      9995   \n",
       "0     0.023356  0.026224  0.026569  ...  0.037966  0.030364  0.037545  \\\n",
       "1     0.008013  0.008664  0.008923  ...  0.014496  0.024966  0.027437   \n",
       "2     0.018818  0.018637  0.018815  ...  0.024620  0.022942  0.026715   \n",
       "3     0.019116  0.023623  0.024492  ...  0.051312  0.047458  0.049338   \n",
       "4     0.010670  0.008134  0.006513  ...  0.236769  0.217499  0.187244   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2819  0.048257  0.049417  0.049000  ...  0.021169  0.023617  0.033694   \n",
       "2820  0.104169  0.120303  0.125067  ...  0.082375  0.083446  0.096510   \n",
       "2821  0.043914  0.039875  0.037170  ...  0.006903  0.008322  0.011071   \n",
       "2822  0.005400  0.004169  0.005151  ...  0.049241  0.039586  0.050542   \n",
       "2823  0.026609  0.024203  0.020953  ...  0.090198  0.101889  0.105174   \n",
       "\n",
       "          9996      9997      9998      9999  Oxacillin  Clindamycin   \n",
       "0     0.040851  0.034176  0.046110  0.025638        0.0          0.0  \\\n",
       "1     0.026541  0.022940  0.020572  0.032504        0.0          0.0   \n",
       "2     0.032045  0.030431  0.029085  0.013117        0.0          0.0   \n",
       "3     0.055039  0.054541  0.058643  0.058919        0.0          0.0   \n",
       "4     0.216243  0.221910  0.226531  0.221965        0.0          0.0   \n",
       "...        ...       ...       ...       ...        ...          ...   \n",
       "2819  0.021037  0.018727  0.010641  0.009238        0.0          1.0   \n",
       "2820  0.084883  0.092228  0.085599  0.042142        0.0          1.0   \n",
       "2821  0.010274  0.004682  0.003547  0.001744        0.0          0.0   \n",
       "2822  0.039139  0.046816  0.043036  0.037402        1.0          1.0   \n",
       "2823  0.122065  0.095740  0.082289  0.081714        0.0          0.0   \n",
       "\n",
       "      Fusidic acid  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "...            ...  \n",
       "2819           0.0  \n",
       "2820           0.0  \n",
       "2821           0.0  \n",
       "2822           0.0  \n",
       "2823           0.0  \n",
       "\n",
       "[2824 rows x 8003 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = \"data/processed/raw/train_s_aureus_driams.csv\"\n",
    "train_bac = pd.read_csv(train_file)\n",
    "train_bac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>...</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>Oxacillin</th>\n",
       "      <th>Clindamycin</th>\n",
       "      <th>Fusidic acid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044453</td>\n",
       "      <td>0.032486</td>\n",
       "      <td>0.032540</td>\n",
       "      <td>0.034223</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.039503</td>\n",
       "      <td>0.031378</td>\n",
       "      <td>0.035506</td>\n",
       "      <td>0.037688</td>\n",
       "      <td>0.035658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247814</td>\n",
       "      <td>0.263833</td>\n",
       "      <td>0.279904</td>\n",
       "      <td>0.264432</td>\n",
       "      <td>0.241573</td>\n",
       "      <td>0.266020</td>\n",
       "      <td>0.231517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033364</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.066426</td>\n",
       "      <td>0.057485</td>\n",
       "      <td>0.052903</td>\n",
       "      <td>0.050839</td>\n",
       "      <td>0.036631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026184</td>\n",
       "      <td>0.026459</td>\n",
       "      <td>0.025393</td>\n",
       "      <td>0.028609</td>\n",
       "      <td>0.031314</td>\n",
       "      <td>0.031739</td>\n",
       "      <td>0.033337</td>\n",
       "      <td>0.028051</td>\n",
       "      <td>0.028047</td>\n",
       "      <td>0.028978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086746</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.094103</td>\n",
       "      <td>0.080969</td>\n",
       "      <td>0.073970</td>\n",
       "      <td>0.069047</td>\n",
       "      <td>0.070988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015010</td>\n",
       "      <td>0.017782</td>\n",
       "      <td>0.014582</td>\n",
       "      <td>0.015084</td>\n",
       "      <td>0.018046</td>\n",
       "      <td>0.014461</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.018769</td>\n",
       "      <td>0.018272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.007583</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060499</td>\n",
       "      <td>0.043034</td>\n",
       "      <td>0.030296</td>\n",
       "      <td>0.032635</td>\n",
       "      <td>0.031272</td>\n",
       "      <td>0.032762</td>\n",
       "      <td>0.031154</td>\n",
       "      <td>0.030382</td>\n",
       "      <td>0.030233</td>\n",
       "      <td>0.029438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029452</td>\n",
       "      <td>0.033288</td>\n",
       "      <td>0.039230</td>\n",
       "      <td>0.046477</td>\n",
       "      <td>0.037219</td>\n",
       "      <td>0.022227</td>\n",
       "      <td>0.019920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0.013092</td>\n",
       "      <td>0.011730</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>0.013513</td>\n",
       "      <td>0.015317</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>0.013338</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050851</td>\n",
       "      <td>0.046334</td>\n",
       "      <td>0.042840</td>\n",
       "      <td>0.061644</td>\n",
       "      <td>0.066948</td>\n",
       "      <td>0.061007</td>\n",
       "      <td>0.056178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>0.021222</td>\n",
       "      <td>0.015896</td>\n",
       "      <td>0.015512</td>\n",
       "      <td>0.017995</td>\n",
       "      <td>0.018663</td>\n",
       "      <td>0.019427</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.014589</td>\n",
       "      <td>0.016765</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047285</td>\n",
       "      <td>0.056455</td>\n",
       "      <td>0.058002</td>\n",
       "      <td>0.055528</td>\n",
       "      <td>0.043539</td>\n",
       "      <td>0.039962</td>\n",
       "      <td>0.034761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0.045613</td>\n",
       "      <td>0.041040</td>\n",
       "      <td>0.046177</td>\n",
       "      <td>0.050216</td>\n",
       "      <td>0.046525</td>\n",
       "      <td>0.048843</td>\n",
       "      <td>0.045920</td>\n",
       "      <td>0.044283</td>\n",
       "      <td>0.043983</td>\n",
       "      <td>0.046330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104234</td>\n",
       "      <td>0.094692</td>\n",
       "      <td>0.090012</td>\n",
       "      <td>0.096624</td>\n",
       "      <td>0.092228</td>\n",
       "      <td>0.100024</td>\n",
       "      <td>0.043682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>0.015193</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>0.010877</td>\n",
       "      <td>0.009975</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.010783</td>\n",
       "      <td>0.013170</td>\n",
       "      <td>0.014157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051772</td>\n",
       "      <td>0.058255</td>\n",
       "      <td>0.074609</td>\n",
       "      <td>0.068249</td>\n",
       "      <td>0.049157</td>\n",
       "      <td>0.070229</td>\n",
       "      <td>0.043615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>0.025453</td>\n",
       "      <td>0.022209</td>\n",
       "      <td>0.022442</td>\n",
       "      <td>0.025181</td>\n",
       "      <td>0.025069</td>\n",
       "      <td>0.025761</td>\n",
       "      <td>0.022690</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.022596</td>\n",
       "      <td>0.025572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052692</td>\n",
       "      <td>0.061853</td>\n",
       "      <td>0.048375</td>\n",
       "      <td>0.060665</td>\n",
       "      <td>0.043305</td>\n",
       "      <td>0.041617</td>\n",
       "      <td>0.048284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 8003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2000      2001      2002      2003      2004      2005      2006   \n",
       "0    0.044453  0.032486  0.032540  0.034223  0.037528  0.039503  0.031378  \\\n",
       "1    0.004318  0.001881  0.001274  0.000902  0.000892  0.000049  0.002188   \n",
       "2    0.026184  0.026459  0.025393  0.028609  0.031314  0.031739  0.033337   \n",
       "3    0.000000  0.015010  0.017782  0.014582  0.015084  0.018046  0.014461   \n",
       "4    0.060499  0.043034  0.030296  0.032635  0.031272  0.032762  0.031154   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "702  0.013092  0.011730  0.009902  0.013513  0.015317  0.011370  0.013338   \n",
       "703  0.021222  0.015896  0.015512  0.017995  0.018663  0.019427  0.018667   \n",
       "704  0.045613  0.041040  0.046177  0.050216  0.046525  0.048843  0.045920   \n",
       "705  0.015193  0.011922  0.010877  0.009975  0.010474  0.012171  0.010417   \n",
       "706  0.025453  0.022209  0.022442  0.025181  0.025069  0.025761  0.022690   \n",
       "\n",
       "         2007      2008      2009  ...      9993      9994      9995   \n",
       "0    0.035506  0.037688  0.035658  ...  0.247814  0.263833  0.279904  \\\n",
       "1    0.002001  0.003081  0.003384  ...  0.033364  0.042735  0.066426   \n",
       "2    0.028051  0.028047  0.028978  ...  0.086746  0.087719  0.094103   \n",
       "3    0.014400  0.018769  0.018272  ...  0.005062  0.006748  0.004573   \n",
       "4    0.030382  0.030233  0.029438  ...  0.029452  0.033288  0.039230   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "702  0.010117  0.010994  0.009222  ...  0.050851  0.046334  0.042840   \n",
       "703  0.014589  0.016765  0.015071  ...  0.047285  0.056455  0.058002   \n",
       "704  0.044283  0.043983  0.046330  ...  0.104234  0.094692  0.090012   \n",
       "705  0.010783  0.013170  0.014157  ...  0.051772  0.058255  0.074609   \n",
       "706  0.024250  0.022596  0.025572  ...  0.052692  0.061853  0.048375   \n",
       "\n",
       "         9996      9997      9998      9999  Oxacillin  Clindamycin   \n",
       "0    0.264432  0.241573  0.266020  0.231517        0.0          0.0  \\\n",
       "1    0.057485  0.052903  0.050839  0.036631        0.0          0.0   \n",
       "2    0.080969  0.073970  0.069047  0.070988        0.0          1.0   \n",
       "3    0.007583  0.008427  0.004729  0.002394        0.0          0.0   \n",
       "4    0.046477  0.037219  0.022227  0.019920        0.0          0.0   \n",
       "..        ...       ...       ...       ...        ...          ...   \n",
       "702  0.061644  0.066948  0.061007  0.056178        0.0          0.0   \n",
       "703  0.055528  0.043539  0.039962  0.034761        1.0          0.0   \n",
       "704  0.096624  0.092228  0.100024  0.043682        0.0          0.0   \n",
       "705  0.068249  0.049157  0.070229  0.043615        1.0          0.0   \n",
       "706  0.060665  0.043305  0.041617  0.048284        0.0          0.0   \n",
       "\n",
       "     Fusidic acid  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             1.0  \n",
       "4             0.0  \n",
       "..            ...  \n",
       "702           0.0  \n",
       "703           0.0  \n",
       "704           1.0  \n",
       "705           0.0  \n",
       "706           0.0  \n",
       "\n",
       "[707 rows x 8003 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = \"data/processed/raw/test_s_aureus_driams.csv\"\n",
    "test_bac = pd.read_csv(test_file)\n",
    "test_bac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rXEshQwKQuzR",
    "outputId": "32756288-dd35-49f1-be9b-34bfe433baf7",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_x = train_bac[train_bac.columns.drop(list(train_bac.filter(regex='[^0-9]')))]\n",
    "test_x = test_bac[test_bac.columns.drop(list(test_bac.filter(regex='[^0-9]')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GiCCaGOEQuzS",
    "outputId": "bdc15429-4a19-4332-d59f-dd1c0ce37d88",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "antibiotics = train_bac.columns.drop(train_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_bac[antibiotics]\n",
    "test_y = test_bac[antibiotics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def multilabel_f1_wrapper(true, pred, average=\"weighted\"):\n",
    "    if isinstance(true, list):\n",
    "        true = np.array(true)\n",
    "    elif isinstance(true, pd.DataFrame):\n",
    "        true = true.to_numpy()\n",
    "    if isinstance(pred, list):\n",
    "        pred = np.array(pred)\n",
    "    elif isinstance(true, pd.DataFrame):\n",
    "        pred = pred.to_numpy()\n",
    "    column = 0\n",
    "    total = 0\n",
    "    while column < true[0].size:\n",
    "        total+=f1_score(true[:, column], pred[:, column], average=average)\n",
    "        column+=1\n",
    "    return total/(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def report(true, pred):\n",
    "        \n",
    "    hl = hamming_loss(true, pred)\n",
    "    f1w = multilabel_f1_wrapper(true, pred, \"weighted\")\n",
    "    acc = accuracy_score(true, pred)\n",
    "    \n",
    "    f1u = multilabel_f1_wrapper(true, pred, \"macro\")\n",
    "    f1su = f1_score(true, pred, average=\"macro\")\n",
    "    f1sw = f1_score(true, pred, average=\"weighted\")\n",
    "\n",
    "    \n",
    "    print(\"Main metrics:\")\n",
    "    print(\" Hamming Loss:\", hl)\n",
    "    print(\" Accuracy:\", acc)\n",
    "    print(\" F1 Score (Weighted):\", f1w)\n",
    "    print(\"================================================\")\n",
    "    print(\"Other metrics:\")\n",
    "    print(\" F1 Score (Unweighted):\", f1u)\n",
    "    print(\" F1 Score (sklearn Unweighted):\", f1su)\n",
    "    print(\" F1 Score (sklearn Weighted):\", f1sw)\n",
    "    return hl, acc, f1w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-gP_gv8QuzZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eocque/bac/venv/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eocque/bac/venv/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eocque/bac/venv/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eocque/bac/venv/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eocque/bac/venv/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eocque/bac/venv/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eocque/bac/venv/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best score: 0.8840968763649186\n",
      "Best parameter combination found: OrderedDict([('base_estimator__C', 1000.0), ('base_estimator__gamma', 0.0021319174418543713), ('base_estimator__kernel', 'rbf')])\n"
     ]
    }
   ],
   "source": [
    "bayesopt = BayesSearchCV(\n",
    "    ClassifierChain(SVC(), random_state=0),\n",
    "    {\n",
    "        \"base_estimator__C\": Real(1e-6, 1000, prior=\"log-uniform\"),\n",
    "        \"base_estimator__kernel\": Categorical([\"rbf\"]),\n",
    "        \"base_estimator__gamma\": Real(1e-6, 1000, prior=\"log-uniform\"),\n",
    "    },\n",
    "    n_iter=250,\n",
    "    cv=5,\n",
    "    random_state=0,\n",
    "    n_jobs=1,\n",
    "    n_points=1,\n",
    "    scoring=make_scorer(multilabel_f1_wrapper),\n",
    "    verbose=1,\n",
    ")\n",
    "bayesopt.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best iteration: 172\n",
      "Split scores:\n",
      " 0 0.8860454802133789\n",
      " 1 0.8907669202753912\n",
      " 2 0.8808700239869293\n",
      " 3 0.8825473456231882\n",
      " 4 0.8802546117257064\n",
      "Mean score: 0.8840968763649186\n",
      "Best parameter combination found: OrderedDict([('base_estimator__C', 1000.0), ('base_estimator__gamma', 0.0021319174418543713), ('base_estimator__kernel', 'rbf')])\n"
     ]
    }
   ],
   "source": [
    "best_iteration = 0\n",
    "for i in range(0, 250):\n",
    "    if bayesopt.cv_results_[\"mean_test_score\"][i] == bayesopt.best_score_:\n",
    "        best_iteration = i\n",
    "print(\"Best iteration:\", best_iteration)\n",
    "print(\"Split scores:\")\n",
    "for i in range(0, 5):\n",
    "    print(\"\", i, bayesopt.cv_results_[\"split\"+str(i)+\"_test_score\"][best_iteration])\n",
    "    \n",
    "print(\"Mean score:\", bayesopt.best_score_)\n",
    "print(\"Best parameter combination found:\", bayesopt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"svm_s_aureus_raw.joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_s_aureus_raw.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(bayesopt.best_estimator_, model_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main metrics:\n",
      " Hamming Loss: 0.10089580386610089\n",
      " Accuracy: 0.7468175388967468\n",
      " F1 Score (Weighted): 0.8860353920359451\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.6957249709862673\n",
      " F1 Score (sklearn Unweighted): 0.4489927079471017\n",
      " F1 Score (sklearn Weighted): 0.5228128652494827\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y) \n",
    "pred = model.predict(test_x)\n",
    "model_hl, model_acc, model_f1 = report(test_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, len(antibiotics), figsize=(len(antibiotics)*5, 5))\n",
    "fig.supxlabel(\"Predicted Label\")\n",
    "fig.supylabel(\"True Label\")\n",
    "\n",
    "cm_svm_c = multilabel_confusion_matrix(test_y, pred)\n",
    "\n",
    "for i in range(len(antibiotics)):\n",
    "  sns.heatmap(ax=axes[i], data=cm_svm_c[i], annot=True, fmt='d', cbar=None, cmap=\"Blues\", xticklabels=[\"S\", \"R\"], yticklabels=[\"S\", \"R\"]).set(title=antibiotics[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CalibratedClassifierCV(cv=5, estimator=SVC())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CalibratedClassifierCV</label><div class=\"sk-toggleable__content\"><pre>CalibratedClassifierCV(cv=5, estimator=SVC())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "CalibratedClassifierCV(cv=5, estimator=SVC())"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrated_model = CalibratedClassifierCV(SVC(), cv=5)\n",
    "calibrated_model.fit(train_x, train_y[\"Oxacillin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = calibrated_model.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85897675, 0.14102325],\n",
       "       [0.87936035, 0.12063965],\n",
       "       [0.88336466, 0.11663534],\n",
       "       ...,\n",
       "       [0.71671151, 0.28328849],\n",
       "       [0.58974178, 0.41025822],\n",
       "       [0.79581778, 0.20418222]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for antibiotic Oxacillin\n",
      " Mean TP: 0.7359529449168063\n",
      " Mean TN: 0.32437372311376755\n",
      " Mean FP: 0.8770620170040351\n",
      " Mean FN: 0.21331364503906314\n"
     ]
    }
   ],
   "source": [
    "    antibiotic = 0\n",
    "    count_tp = 0\n",
    "    count_tn = 0\n",
    "    count_fp = 0\n",
    "    count_fn = 0\n",
    "    sum_tp = 0\n",
    "    sum_tn = 0\n",
    "    sum_fp = 0\n",
    "    sum_fn = 0\n",
    "    for i in range(len(proba[:, antibiotic])):\n",
    "        disc_pred = int(proba[i, antibiotic] > 0.5)\n",
    "        if disc_pred == 1:\n",
    "            if disc_pred == test_y.iloc[i, antibiotic]:\n",
    "                count_tp += 1\n",
    "                sum_tp += proba[i, antibiotic]\n",
    "            else:\n",
    "                count_fp += 1\n",
    "                sum_fp += proba[i, antibiotic]\n",
    "        else:\n",
    "            if disc_pred == test_y.iloc[i, antibiotic]:\n",
    "                count_tn += 1\n",
    "                sum_tn += proba[i, antibiotic]\n",
    "            else:\n",
    "                count_fn += 1\n",
    "                sum_fn += proba[i, antibiotic]\n",
    "    print(\"Results for antibiotic\", antibiotics[antibiotic])\n",
    "    if count_tp == 0:\n",
    "        print(\" Mean TP: None\")\n",
    "    else: \n",
    "        print(\" Mean TP:\", sum_tp/count_tp)\n",
    "    if count_tn == 0:\n",
    "        print(\" Mean TN: None\")\n",
    "    else: \n",
    "        print(\" Mean TN:\", sum_tn/count_tn)\n",
    "    if count_fp == 0:\n",
    "        print(\" Mean FP: None\")\n",
    "    else: \n",
    "        print(\" Mean FP:\", sum_fp/count_fp)\n",
    "    if count_fn == 0:\n",
    "        print(\" Mean FN: None\")\n",
    "    else: \n",
    "        print(\" Mean FN:\", sum_fn/count_fn)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
