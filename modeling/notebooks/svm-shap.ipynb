{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/castudil/bacteria-multi-label/blob/main/multilabel_bac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKUeIuZcpHUl"
   },
   "source": [
    "Libraries used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bzVprbfpWSLa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Development\\miniconda3\\envs\\bacml\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import (f1_score, multilabel_confusion_matrix,\n",
    "                             accuracy_score, hamming_loss, jaccard_score, make_scorer)\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import shap\n",
    "import torch\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "nQsWnulDWdDD",
    "outputId": "6f97687c-b560-4e34-fd8b-9c3ef7aeb0c7",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2020</th>\n",
       "      <th>2040</th>\n",
       "      <th>2060</th>\n",
       "      <th>2080</th>\n",
       "      <th>2100</th>\n",
       "      <th>2120</th>\n",
       "      <th>2140</th>\n",
       "      <th>2160</th>\n",
       "      <th>2180</th>\n",
       "      <th>...</th>\n",
       "      <th>9860</th>\n",
       "      <th>9880</th>\n",
       "      <th>9900</th>\n",
       "      <th>9920</th>\n",
       "      <th>9940</th>\n",
       "      <th>9960</th>\n",
       "      <th>9980</th>\n",
       "      <th>Oxacillin</th>\n",
       "      <th>Clindamycin</th>\n",
       "      <th>Fusidic acid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.286217</td>\n",
       "      <td>-0.263798</td>\n",
       "      <td>-0.185108</td>\n",
       "      <td>-0.460499</td>\n",
       "      <td>-0.340950</td>\n",
       "      <td>-0.140792</td>\n",
       "      <td>-0.224080</td>\n",
       "      <td>-0.401850</td>\n",
       "      <td>-0.324227</td>\n",
       "      <td>0.033580</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.523652</td>\n",
       "      <td>-0.499112</td>\n",
       "      <td>-0.496468</td>\n",
       "      <td>-0.558968</td>\n",
       "      <td>-0.476363</td>\n",
       "      <td>-0.511347</td>\n",
       "      <td>-0.534530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.551211</td>\n",
       "      <td>-0.571190</td>\n",
       "      <td>-0.567694</td>\n",
       "      <td>-0.682123</td>\n",
       "      <td>-0.626766</td>\n",
       "      <td>-0.625056</td>\n",
       "      <td>-0.681753</td>\n",
       "      <td>-0.698166</td>\n",
       "      <td>-0.694874</td>\n",
       "      <td>-0.655262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.843329</td>\n",
       "      <td>-0.786038</td>\n",
       "      <td>-0.779041</td>\n",
       "      <td>-0.730581</td>\n",
       "      <td>-0.736446</td>\n",
       "      <td>-0.665822</td>\n",
       "      <td>-0.654775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.286692</td>\n",
       "      <td>-0.298551</td>\n",
       "      <td>-0.273101</td>\n",
       "      <td>-0.149969</td>\n",
       "      <td>-0.227278</td>\n",
       "      <td>-0.219336</td>\n",
       "      <td>-0.295638</td>\n",
       "      <td>-0.411640</td>\n",
       "      <td>-0.279910</td>\n",
       "      <td>-0.341791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.728511</td>\n",
       "      <td>-0.710503</td>\n",
       "      <td>-0.635119</td>\n",
       "      <td>-0.617323</td>\n",
       "      <td>-0.605996</td>\n",
       "      <td>-0.633157</td>\n",
       "      <td>-0.635633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.317437</td>\n",
       "      <td>-0.007199</td>\n",
       "      <td>-0.186219</td>\n",
       "      <td>-0.218208</td>\n",
       "      <td>-0.295089</td>\n",
       "      <td>-0.320160</td>\n",
       "      <td>-0.353085</td>\n",
       "      <td>-0.465764</td>\n",
       "      <td>-0.178849</td>\n",
       "      <td>-0.214500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.487951</td>\n",
       "      <td>-0.449209</td>\n",
       "      <td>-0.286415</td>\n",
       "      <td>-0.273146</td>\n",
       "      <td>-0.305423</td>\n",
       "      <td>-0.280417</td>\n",
       "      <td>-0.299386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.510705</td>\n",
       "      <td>-0.506801</td>\n",
       "      <td>-0.561659</td>\n",
       "      <td>-0.685221</td>\n",
       "      <td>-0.596548</td>\n",
       "      <td>-0.506514</td>\n",
       "      <td>-0.510323</td>\n",
       "      <td>0.121535</td>\n",
       "      <td>-0.525663</td>\n",
       "      <td>-0.524299</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018196</td>\n",
       "      <td>0.824586</td>\n",
       "      <td>1.432266</td>\n",
       "      <td>1.421755</td>\n",
       "      <td>1.191401</td>\n",
       "      <td>1.256895</td>\n",
       "      <td>1.746369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>0.249296</td>\n",
       "      <td>0.248307</td>\n",
       "      <td>0.264162</td>\n",
       "      <td>0.193118</td>\n",
       "      <td>0.250260</td>\n",
       "      <td>0.321630</td>\n",
       "      <td>0.206245</td>\n",
       "      <td>0.214599</td>\n",
       "      <td>0.265692</td>\n",
       "      <td>0.190006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.772152</td>\n",
       "      <td>-0.467501</td>\n",
       "      <td>-0.589754</td>\n",
       "      <td>-0.633639</td>\n",
       "      <td>-0.698323</td>\n",
       "      <td>-0.675144</td>\n",
       "      <td>-0.704980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>1.785533</td>\n",
       "      <td>1.823061</td>\n",
       "      <td>2.178447</td>\n",
       "      <td>1.698854</td>\n",
       "      <td>1.434265</td>\n",
       "      <td>1.664576</td>\n",
       "      <td>1.464162</td>\n",
       "      <td>1.581346</td>\n",
       "      <td>1.956586</td>\n",
       "      <td>1.645609</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159264</td>\n",
       "      <td>0.090428</td>\n",
       "      <td>0.101984</td>\n",
       "      <td>0.266643</td>\n",
       "      <td>0.136130</td>\n",
       "      <td>0.155044</td>\n",
       "      <td>0.115017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>0.089459</td>\n",
       "      <td>0.270119</td>\n",
       "      <td>0.243205</td>\n",
       "      <td>0.641778</td>\n",
       "      <td>0.398895</td>\n",
       "      <td>0.409032</td>\n",
       "      <td>0.425259</td>\n",
       "      <td>0.431668</td>\n",
       "      <td>0.485349</td>\n",
       "      <td>0.216998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.945420</td>\n",
       "      <td>-0.887857</td>\n",
       "      <td>-0.932228</td>\n",
       "      <td>-0.931200</td>\n",
       "      <td>-0.937917</td>\n",
       "      <td>-0.937877</td>\n",
       "      <td>-0.928717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>-0.604482</td>\n",
       "      <td>-0.637415</td>\n",
       "      <td>-0.639497</td>\n",
       "      <td>-0.736734</td>\n",
       "      <td>-0.680152</td>\n",
       "      <td>-0.666202</td>\n",
       "      <td>-0.695422</td>\n",
       "      <td>-0.827097</td>\n",
       "      <td>-0.728076</td>\n",
       "      <td>-0.665091</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.514248</td>\n",
       "      <td>-0.564228</td>\n",
       "      <td>-0.552775</td>\n",
       "      <td>-0.479549</td>\n",
       "      <td>-0.461669</td>\n",
       "      <td>-0.460116</td>\n",
       "      <td>-0.485656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>-0.181360</td>\n",
       "      <td>-0.123142</td>\n",
       "      <td>-0.135677</td>\n",
       "      <td>-0.095399</td>\n",
       "      <td>-0.124620</td>\n",
       "      <td>-0.151726</td>\n",
       "      <td>-0.161469</td>\n",
       "      <td>-0.212155</td>\n",
       "      <td>-0.088708</td>\n",
       "      <td>-0.211027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074539</td>\n",
       "      <td>0.120027</td>\n",
       "      <td>0.257327</td>\n",
       "      <td>0.195943</td>\n",
       "      <td>0.311396</td>\n",
       "      <td>0.249750</td>\n",
       "      <td>0.353902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2824 rows × 403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          2000      2020      2040      2060      2080      2100      2120  \\\n",
       "0    -0.286217 -0.263798 -0.185108 -0.460499 -0.340950 -0.140792 -0.224080   \n",
       "1    -0.551211 -0.571190 -0.567694 -0.682123 -0.626766 -0.625056 -0.681753   \n",
       "2    -0.286692 -0.298551 -0.273101 -0.149969 -0.227278 -0.219336 -0.295638   \n",
       "3    -0.317437 -0.007199 -0.186219 -0.218208 -0.295089 -0.320160 -0.353085   \n",
       "4    -0.510705 -0.506801 -0.561659 -0.685221 -0.596548 -0.506514 -0.510323   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2819  0.249296  0.248307  0.264162  0.193118  0.250260  0.321630  0.206245   \n",
       "2820  1.785533  1.823061  2.178447  1.698854  1.434265  1.664576  1.464162   \n",
       "2821  0.089459  0.270119  0.243205  0.641778  0.398895  0.409032  0.425259   \n",
       "2822 -0.604482 -0.637415 -0.639497 -0.736734 -0.680152 -0.666202 -0.695422   \n",
       "2823 -0.181360 -0.123142 -0.135677 -0.095399 -0.124620 -0.151726 -0.161469   \n",
       "\n",
       "          2140      2160      2180  ...      9860      9880      9900  \\\n",
       "0    -0.401850 -0.324227  0.033580  ... -0.523652 -0.499112 -0.496468   \n",
       "1    -0.698166 -0.694874 -0.655262  ... -0.843329 -0.786038 -0.779041   \n",
       "2    -0.411640 -0.279910 -0.341791  ... -0.728511 -0.710503 -0.635119   \n",
       "3    -0.465764 -0.178849 -0.214500  ... -0.487951 -0.449209 -0.286415   \n",
       "4     0.121535 -0.525663 -0.524299  ...  1.018196  0.824586  1.432266   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2819  0.214599  0.265692  0.190006  ... -0.772152 -0.467501 -0.589754   \n",
       "2820  1.581346  1.956586  1.645609  ... -0.159264  0.090428  0.101984   \n",
       "2821  0.431668  0.485349  0.216998  ... -0.945420 -0.887857 -0.932228   \n",
       "2822 -0.827097 -0.728076 -0.665091  ... -0.514248 -0.564228 -0.552775   \n",
       "2823 -0.212155 -0.088708 -0.211027  ...  0.074539  0.120027  0.257327   \n",
       "\n",
       "          9920      9940      9960      9980  Oxacillin  Clindamycin  \\\n",
       "0    -0.558968 -0.476363 -0.511347 -0.534530        0.0          0.0   \n",
       "1    -0.730581 -0.736446 -0.665822 -0.654775        0.0          0.0   \n",
       "2    -0.617323 -0.605996 -0.633157 -0.635633        0.0          0.0   \n",
       "3    -0.273146 -0.305423 -0.280417 -0.299386        0.0          0.0   \n",
       "4     1.421755  1.191401  1.256895  1.746369        0.0          0.0   \n",
       "...        ...       ...       ...       ...        ...          ...   \n",
       "2819 -0.633639 -0.698323 -0.675144 -0.704980        0.0          1.0   \n",
       "2820  0.266643  0.136130  0.155044  0.115017        0.0          1.0   \n",
       "2821 -0.931200 -0.937917 -0.937877 -0.928717        0.0          0.0   \n",
       "2822 -0.479549 -0.461669 -0.460116 -0.485656        1.0          1.0   \n",
       "2823  0.195943  0.311396  0.249750  0.353902        0.0          0.0   \n",
       "\n",
       "      Fusidic acid  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "...            ...  \n",
       "2819           0.0  \n",
       "2820           0.0  \n",
       "2821           0.0  \n",
       "2822           0.0  \n",
       "2823           0.0  \n",
       "\n",
       "[2824 rows x 403 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = \"data/processed/binned/standard/train_s_aureus_driams_bin20.csv\"\n",
    "train_bac = pd.read_csv(train_file)\n",
    "train_bac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2020</th>\n",
       "      <th>2040</th>\n",
       "      <th>2060</th>\n",
       "      <th>2080</th>\n",
       "      <th>2100</th>\n",
       "      <th>2120</th>\n",
       "      <th>2140</th>\n",
       "      <th>2160</th>\n",
       "      <th>2180</th>\n",
       "      <th>...</th>\n",
       "      <th>9860</th>\n",
       "      <th>9880</th>\n",
       "      <th>9900</th>\n",
       "      <th>9920</th>\n",
       "      <th>9940</th>\n",
       "      <th>9960</th>\n",
       "      <th>9980</th>\n",
       "      <th>Oxacillin</th>\n",
       "      <th>Clindamycin</th>\n",
       "      <th>Fusidic acid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104186</td>\n",
       "      <td>0.110324</td>\n",
       "      <td>0.045273</td>\n",
       "      <td>0.093256</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>0.020650</td>\n",
       "      <td>0.021929</td>\n",
       "      <td>0.172607</td>\n",
       "      <td>0.072579</td>\n",
       "      <td>...</td>\n",
       "      <td>2.509083</td>\n",
       "      <td>2.029358</td>\n",
       "      <td>2.289490</td>\n",
       "      <td>2.349229</td>\n",
       "      <td>2.329039</td>\n",
       "      <td>2.450476</td>\n",
       "      <td>2.464367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.683329</td>\n",
       "      <td>-0.682614</td>\n",
       "      <td>-0.700279</td>\n",
       "      <td>-0.772893</td>\n",
       "      <td>-0.734363</td>\n",
       "      <td>-0.680305</td>\n",
       "      <td>-0.712202</td>\n",
       "      <td>-0.504519</td>\n",
       "      <td>-0.739549</td>\n",
       "      <td>-0.717521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.758693</td>\n",
       "      <td>-0.690376</td>\n",
       "      <td>-0.661395</td>\n",
       "      <td>-0.617496</td>\n",
       "      <td>-0.522159</td>\n",
       "      <td>-0.508605</td>\n",
       "      <td>-0.429725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.126579</td>\n",
       "      <td>-0.080111</td>\n",
       "      <td>-0.088407</td>\n",
       "      <td>-0.004778</td>\n",
       "      <td>-0.107682</td>\n",
       "      <td>-0.076610</td>\n",
       "      <td>-0.099526</td>\n",
       "      <td>-0.182381</td>\n",
       "      <td>-0.138457</td>\n",
       "      <td>-0.201429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064662</td>\n",
       "      <td>-0.165242</td>\n",
       "      <td>0.094636</td>\n",
       "      <td>0.190332</td>\n",
       "      <td>0.271641</td>\n",
       "      <td>0.152851</td>\n",
       "      <td>0.115044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.393258</td>\n",
       "      <td>-0.391113</td>\n",
       "      <td>-0.381737</td>\n",
       "      <td>-0.364848</td>\n",
       "      <td>-0.337233</td>\n",
       "      <td>-0.363708</td>\n",
       "      <td>-0.367530</td>\n",
       "      <td>-0.309146</td>\n",
       "      <td>-0.398401</td>\n",
       "      <td>-0.417081</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897556</td>\n",
       "      <td>-0.906563</td>\n",
       "      <td>-0.933985</td>\n",
       "      <td>-0.920237</td>\n",
       "      <td>-0.925019</td>\n",
       "      <td>-0.922054</td>\n",
       "      <td>-0.932670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084063</td>\n",
       "      <td>-0.057955</td>\n",
       "      <td>-0.069780</td>\n",
       "      <td>-0.221597</td>\n",
       "      <td>-0.068780</td>\n",
       "      <td>-0.093904</td>\n",
       "      <td>-0.131015</td>\n",
       "      <td>-0.165511</td>\n",
       "      <td>-0.178512</td>\n",
       "      <td>-0.102924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.479673</td>\n",
       "      <td>-0.348515</td>\n",
       "      <td>-0.551896</td>\n",
       "      <td>-0.588232</td>\n",
       "      <td>-0.607792</td>\n",
       "      <td>-0.637152</td>\n",
       "      <td>-0.585738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>-0.485712</td>\n",
       "      <td>-0.436828</td>\n",
       "      <td>-0.444883</td>\n",
       "      <td>-0.438499</td>\n",
       "      <td>-0.477204</td>\n",
       "      <td>-0.447962</td>\n",
       "      <td>-0.500632</td>\n",
       "      <td>-0.649616</td>\n",
       "      <td>-0.488410</td>\n",
       "      <td>-0.359514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.434061</td>\n",
       "      <td>-0.449801</td>\n",
       "      <td>-0.258621</td>\n",
       "      <td>-0.228516</td>\n",
       "      <td>-0.194811</td>\n",
       "      <td>-0.291070</td>\n",
       "      <td>-0.191354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>-0.363197</td>\n",
       "      <td>-0.367166</td>\n",
       "      <td>-0.352612</td>\n",
       "      <td>-0.385939</td>\n",
       "      <td>-0.376585</td>\n",
       "      <td>-0.375591</td>\n",
       "      <td>-0.336656</td>\n",
       "      <td>-0.224120</td>\n",
       "      <td>-0.396143</td>\n",
       "      <td>-0.400442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123281</td>\n",
       "      <td>-0.449327</td>\n",
       "      <td>-0.307500</td>\n",
       "      <td>-0.303360</td>\n",
       "      <td>-0.293913</td>\n",
       "      <td>-0.293342</td>\n",
       "      <td>-0.312114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0.238776</td>\n",
       "      <td>0.234833</td>\n",
       "      <td>0.245708</td>\n",
       "      <td>0.542942</td>\n",
       "      <td>0.288722</td>\n",
       "      <td>0.223289</td>\n",
       "      <td>0.272952</td>\n",
       "      <td>0.391740</td>\n",
       "      <td>0.246997</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380082</td>\n",
       "      <td>0.359241</td>\n",
       "      <td>0.284242</td>\n",
       "      <td>0.318265</td>\n",
       "      <td>0.313519</td>\n",
       "      <td>0.319468</td>\n",
       "      <td>0.226947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>-0.480531</td>\n",
       "      <td>-0.494409</td>\n",
       "      <td>-0.504593</td>\n",
       "      <td>-0.593396</td>\n",
       "      <td>-0.539916</td>\n",
       "      <td>-0.530114</td>\n",
       "      <td>-0.595922</td>\n",
       "      <td>-0.720296</td>\n",
       "      <td>-0.577149</td>\n",
       "      <td>-0.533768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.424826</td>\n",
       "      <td>-0.123627</td>\n",
       "      <td>-0.056155</td>\n",
       "      <td>-0.176721</td>\n",
       "      <td>-0.259546</td>\n",
       "      <td>-0.239056</td>\n",
       "      <td>-0.207350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>-0.223659</td>\n",
       "      <td>-0.112314</td>\n",
       "      <td>-0.121260</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>-0.120909</td>\n",
       "      <td>-0.084289</td>\n",
       "      <td>-0.107083</td>\n",
       "      <td>-0.081084</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>-0.132744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158476</td>\n",
       "      <td>-0.327086</td>\n",
       "      <td>-0.241609</td>\n",
       "      <td>-0.190706</td>\n",
       "      <td>-0.131790</td>\n",
       "      <td>-0.167302</td>\n",
       "      <td>-0.257464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2000      2020      2040      2060      2080      2100      2120  \\\n",
       "0    0.104186  0.110324  0.045273  0.093256  0.033230 -0.017189  0.020650   \n",
       "1   -0.683329 -0.682614 -0.700279 -0.772893 -0.734363 -0.680305 -0.712202   \n",
       "2   -0.126579 -0.080111 -0.088407 -0.004778 -0.107682 -0.076610 -0.099526   \n",
       "3   -0.393258 -0.391113 -0.381737 -0.364848 -0.337233 -0.363708 -0.367530   \n",
       "4    0.084063 -0.057955 -0.069780 -0.221597 -0.068780 -0.093904 -0.131015   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "702 -0.485712 -0.436828 -0.444883 -0.438499 -0.477204 -0.447962 -0.500632   \n",
       "703 -0.363197 -0.367166 -0.352612 -0.385939 -0.376585 -0.375591 -0.336656   \n",
       "704  0.238776  0.234833  0.245708  0.542942  0.288722  0.223289  0.272952   \n",
       "705 -0.480531 -0.494409 -0.504593 -0.593396 -0.539916 -0.530114 -0.595922   \n",
       "706 -0.223659 -0.112314 -0.121260  0.029349 -0.120909 -0.084289 -0.107083   \n",
       "\n",
       "         2140      2160      2180  ...      9860      9880      9900  \\\n",
       "0    0.021929  0.172607  0.072579  ...  2.509083  2.029358  2.289490   \n",
       "1   -0.504519 -0.739549 -0.717521  ... -0.758693 -0.690376 -0.661395   \n",
       "2   -0.182381 -0.138457 -0.201429  ... -0.064662 -0.165242  0.094636   \n",
       "3   -0.309146 -0.398401 -0.417081  ... -0.897556 -0.906563 -0.933985   \n",
       "4   -0.165511 -0.178512 -0.102924  ... -0.479673 -0.348515 -0.551896   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "702 -0.649616 -0.488410 -0.359514  ... -0.434061 -0.449801 -0.258621   \n",
       "703 -0.224120 -0.396143 -0.400442  ... -0.123281 -0.449327 -0.307500   \n",
       "704  0.391740  0.246997  0.011889  ...  0.380082  0.359241  0.284242   \n",
       "705 -0.720296 -0.577149 -0.533768  ... -0.424826 -0.123627 -0.056155   \n",
       "706 -0.081084  0.011789 -0.132744  ... -0.158476 -0.327086 -0.241609   \n",
       "\n",
       "         9920      9940      9960      9980  Oxacillin  Clindamycin  \\\n",
       "0    2.349229  2.329039  2.450476  2.464367        0.0          0.0   \n",
       "1   -0.617496 -0.522159 -0.508605 -0.429725        0.0          0.0   \n",
       "2    0.190332  0.271641  0.152851  0.115044        0.0          1.0   \n",
       "3   -0.920237 -0.925019 -0.922054 -0.932670        0.0          0.0   \n",
       "4   -0.588232 -0.607792 -0.637152 -0.585738        0.0          0.0   \n",
       "..        ...       ...       ...       ...        ...          ...   \n",
       "702 -0.228516 -0.194811 -0.291070 -0.191354        0.0          0.0   \n",
       "703 -0.303360 -0.293913 -0.293342 -0.312114        1.0          0.0   \n",
       "704  0.318265  0.313519  0.319468  0.226947        0.0          0.0   \n",
       "705 -0.176721 -0.259546 -0.239056 -0.207350        1.0          0.0   \n",
       "706 -0.190706 -0.131790 -0.167302 -0.257464        0.0          0.0   \n",
       "\n",
       "     Fusidic acid  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             1.0  \n",
       "4             0.0  \n",
       "..            ...  \n",
       "702           0.0  \n",
       "703           0.0  \n",
       "704           1.0  \n",
       "705           0.0  \n",
       "706           0.0  \n",
       "\n",
       "[707 rows x 403 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = \"data/processed/binned/standard/test_s_aureus_driams_bin20.csv\"\n",
    "test_bac = pd.read_csv(test_file)\n",
    "test_bac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rXEshQwKQuzR",
    "outputId": "32756288-dd35-49f1-be9b-34bfe433baf7",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_x = train_bac[train_bac.columns.drop(list(train_bac.filter(regex='[^0-9]')))]\n",
    "test_x = test_bac[test_bac.columns.drop(list(test_bac.filter(regex='[^0-9]')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GiCCaGOEQuzS",
    "outputId": "bdc15429-4a19-4332-d59f-dd1c0ce37d88",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "antibiotics = train_bac.columns.drop(train_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_bac[antibiotics]\n",
    "test_y = test_bac[antibiotics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_lps = pd.DataFrame()\n",
    "train_y_lps[\"Class\"] = train_bac[antibiotics].astype(int).astype(str).agg(''.join, axis=1)\n",
    "train_y_lps[\"Class\"] = train_y_lps[\"Class\"].astype(str)\n",
    "\n",
    "test_y_lps = pd.DataFrame()\n",
    "test_y_lps[\"Class\"] = test_bac[antibiotics].astype(int).astype(str).agg(''.join, axis=1)\n",
    "test_y_lps[\"Class\"] = test_y_lps[\"Class\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = LabelEncoder()\n",
    "lc.fit(train_y_lps.values.ravel())\n",
    "train_y_lps = lc.transform(train_y_lps.values.ravel())\n",
    "test_y_lps = lc.transform(test_y_lps.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms a one-label instance into a multi-label one.\n",
    "def lps_to_multilabel_instance(lps_num):\n",
    "  inverse = lc.inverse_transform([lps_num])\n",
    "  multilabel_instance = []\n",
    "  for result in inverse[0]:\n",
    "      multilabel_instance.append(int(result))\n",
    "  return multilabel_instance\n",
    "\n",
    "# Transforms a list of one-label instances into a multi-label one.\n",
    "def lps_to_multilabel_list(lps_list):\n",
    "  multilabel_list = []\n",
    "  for lps_instance in lps_list:\n",
    "    multilabel_list.append(lps_to_multilabel_instance(lps_instance))\n",
    "  return multilabel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def multilabel_f1_wrapper(true, pred, average=\"weighted\"):\n",
    "    if isinstance(true, list):\n",
    "        true = np.array(true)\n",
    "    elif isinstance(true, pd.DataFrame):\n",
    "        true = true.to_numpy()\n",
    "    if isinstance(pred, list):\n",
    "        pred = np.array(pred)\n",
    "    elif isinstance(true, pd.DataFrame):\n",
    "        pred = pred.to_numpy()\n",
    "    column = 0\n",
    "    total = 0\n",
    "    while column < true[0].size:\n",
    "        total+=f1_score(true[:, column], pred[:, column], average=average)\n",
    "        column+=1\n",
    "    return total/(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lps_f1_wrapper(true, pred, average=\"weighted\"):\n",
    "    non_lps_true = lps_to_multilabel_list(true)\n",
    "    non_lps_pred = lps_to_multilabel_list(pred)\n",
    "    return multilabel_f1_wrapper(non_lps_true, non_lps_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def report(true, pred):\n",
    "    if not len(pred.shape) > 1:\n",
    "        true = lps_to_multilabel_list(true)\n",
    "        pred = lps_to_multilabel_list(pred)\n",
    "        \n",
    "    hl = hamming_loss(true, pred)\n",
    "    f1w = multilabel_f1_wrapper(true, pred, \"weighted\")\n",
    "    acc = accuracy_score(true, pred)\n",
    "    \n",
    "    f1u = multilabel_f1_wrapper(true, pred, \"macro\")\n",
    "    f1su = f1_score(true, pred, average=\"macro\")\n",
    "    f1sw = f1_score(true, pred, average=\"weighted\")\n",
    "\n",
    "    \n",
    "    print(\"Main metrics:\")\n",
    "    print(\" Hamming Loss:\", hl)\n",
    "    print(\" Accuracy:\", acc)\n",
    "    print(\" F1 Score (Weighted):\", f1w)\n",
    "    print(\"================================================\")\n",
    "    print(\"Other metrics:\")\n",
    "    print(\" F1 Score (Unweighted):\", f1u)\n",
    "    print(\" F1 Score (sklearn Unweighted):\", f1su)\n",
    "    print(\" F1 Score (sklearn Weighted):\", f1sw)\n",
    "    return hl, acc, f1w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-gP_gv8QuzZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# opt_lps = BayesSearchCV(\n",
    "#     SVC(),\n",
    "#     {\n",
    "#         \"C\": Real(1e-6, 1000, prior=\"log-uniform\"),\n",
    "#         \"kernel\": Categorical([\"rbf\"]),\n",
    "#         \"gamma\": Real(1e-6, 1000, prior=\"log-uniform\"),\n",
    "#     },\n",
    "#     n_iter=250,\n",
    "#     cv=5,\n",
    "#     random_state=0,\n",
    "#     n_jobs=5,\n",
    "#     n_points=2,\n",
    "#     scoring=make_scorer(lps_f1_wrapper),\n",
    "#     verbose=1\n",
    "# )\n",
    "# np.int = int\n",
    "# opt_lps.fit(train_x, train_y_lps)\n",
    "\n",
    "# print(\"Best score:\", opt_lps.best_score_)\n",
    "# print(\"Best parameter combination found:\", opt_lps.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_lps.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"modeling/models/s_aureus_driams_bin20_svc_standard_lps.joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(opt_lps.best_estimator_, model_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Development\\miniconda3\\envs\\bacml\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.2.2 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main metrics:\n",
      " Hamming Loss: 0.10372465818010372\n",
      " Accuracy: 0.7454031117397454\n",
      " F1 Score (Weighted): 0.8840744114874974\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.6892160547247682\n",
      " F1 Score (sklearn Unweighted): 0.43745935189614227\n",
      " F1 Score (sklearn Weighted): 0.5185201027817817\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_x)\n",
    "model_hl, model_acc, model_f1 = report(test_y_lps, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1000.0, gamma=0.0005358050868072775, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1000.0, gamma=0.0005358050868072775, probability=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1000.0, gamma=0.0005358050868072775, probability=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.probability=True\n",
    "model.fit(train_x, train_y_lps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [1:35:57<3:19:09, 173.18s/it]"
     ]
    }
   ],
   "source": [
    "explainer = shap.KernelExplainer(model.predict_proba, shap.sample(train_x, 100))\n",
    "shap_values = explainer.shap_values(shap.sample(test_x, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'bacml (Python 3.11.5)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# shap.initjs()\n",
    "# shap.force_plot(explainer.expected_value[0], shap_values[..., 0], test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'bacml (Python 3.11.5)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
