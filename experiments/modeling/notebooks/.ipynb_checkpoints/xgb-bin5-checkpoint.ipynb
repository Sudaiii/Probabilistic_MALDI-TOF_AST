{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/castudil/bacteria-multi-label/blob/main/multilabel_bac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKUeIuZcpHUl"
   },
   "source": [
    "Libraries used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bzVprbfpWSLa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import (f1_score, multilabel_confusion_matrix,\n",
    "                             accuracy_score, hamming_loss, jaccard_score, make_scorer)\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from joblib import dump, load\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "nQsWnulDWdDD",
    "outputId": "6f97687c-b560-4e34-fd8b-9c3ef7aeb0c7",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2020</th>\n",
       "      <th>2040</th>\n",
       "      <th>2060</th>\n",
       "      <th>2080</th>\n",
       "      <th>2100</th>\n",
       "      <th>2120</th>\n",
       "      <th>2140</th>\n",
       "      <th>2160</th>\n",
       "      <th>2180</th>\n",
       "      <th>...</th>\n",
       "      <th>9860</th>\n",
       "      <th>9880</th>\n",
       "      <th>9900</th>\n",
       "      <th>9920</th>\n",
       "      <th>9940</th>\n",
       "      <th>9960</th>\n",
       "      <th>9980</th>\n",
       "      <th>Oxacillin</th>\n",
       "      <th>Clindamycin</th>\n",
       "      <th>Fusidic acid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021271</td>\n",
       "      <td>0.021774</td>\n",
       "      <td>0.025388</td>\n",
       "      <td>0.021310</td>\n",
       "      <td>0.022024</td>\n",
       "      <td>0.029203</td>\n",
       "      <td>0.028496</td>\n",
       "      <td>0.030084</td>\n",
       "      <td>0.024553</td>\n",
       "      <td>0.040691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037734</td>\n",
       "      <td>0.034542</td>\n",
       "      <td>0.031264</td>\n",
       "      <td>0.027489</td>\n",
       "      <td>0.035240</td>\n",
       "      <td>0.035080</td>\n",
       "      <td>0.034169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008401</td>\n",
       "      <td>0.007471</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>0.007448</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>0.014959</td>\n",
       "      <td>0.006481</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015979</td>\n",
       "      <td>0.015110</td>\n",
       "      <td>0.014384</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>0.018075</td>\n",
       "      <td>0.024027</td>\n",
       "      <td>0.025398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021248</td>\n",
       "      <td>0.020157</td>\n",
       "      <td>0.021281</td>\n",
       "      <td>0.040733</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>0.025514</td>\n",
       "      <td>0.025027</td>\n",
       "      <td>0.029584</td>\n",
       "      <td>0.026714</td>\n",
       "      <td>0.021601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023793</td>\n",
       "      <td>0.020226</td>\n",
       "      <td>0.022981</td>\n",
       "      <td>0.023913</td>\n",
       "      <td>0.026685</td>\n",
       "      <td>0.026365</td>\n",
       "      <td>0.026794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019755</td>\n",
       "      <td>0.033714</td>\n",
       "      <td>0.025336</td>\n",
       "      <td>0.036465</td>\n",
       "      <td>0.024422</td>\n",
       "      <td>0.020777</td>\n",
       "      <td>0.022242</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>0.031641</td>\n",
       "      <td>0.028074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040163</td>\n",
       "      <td>0.037922</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.045006</td>\n",
       "      <td>0.046522</td>\n",
       "      <td>0.051603</td>\n",
       "      <td>0.051320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.010467</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.012023</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.014732</td>\n",
       "      <td>0.012319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142658</td>\n",
       "      <td>0.124189</td>\n",
       "      <td>0.146476</td>\n",
       "      <td>0.148880</td>\n",
       "      <td>0.145308</td>\n",
       "      <td>0.161595</td>\n",
       "      <td>0.200539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>0.047280</td>\n",
       "      <td>0.045602</td>\n",
       "      <td>0.046357</td>\n",
       "      <td>0.062193</td>\n",
       "      <td>0.052936</td>\n",
       "      <td>0.050927</td>\n",
       "      <td>0.049359</td>\n",
       "      <td>0.061550</td>\n",
       "      <td>0.053316</td>\n",
       "      <td>0.048646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020823</td>\n",
       "      <td>0.036683</td>\n",
       "      <td>0.025691</td>\n",
       "      <td>0.022913</td>\n",
       "      <td>0.020591</td>\n",
       "      <td>0.023360</td>\n",
       "      <td>0.021736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>0.121892</td>\n",
       "      <td>0.118875</td>\n",
       "      <td>0.135706</td>\n",
       "      <td>0.156375</td>\n",
       "      <td>0.114842</td>\n",
       "      <td>0.114014</td>\n",
       "      <td>0.110345</td>\n",
       "      <td>0.131316</td>\n",
       "      <td>0.135759</td>\n",
       "      <td>0.122672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062531</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.067012</td>\n",
       "      <td>0.078088</td>\n",
       "      <td>0.075663</td>\n",
       "      <td>0.082759</td>\n",
       "      <td>0.081547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>0.039517</td>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.045379</td>\n",
       "      <td>0.090256</td>\n",
       "      <td>0.060707</td>\n",
       "      <td>0.055033</td>\n",
       "      <td>0.059977</td>\n",
       "      <td>0.072631</td>\n",
       "      <td>0.064026</td>\n",
       "      <td>0.050019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009032</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.004562</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.004289</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.030132</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.032357</td>\n",
       "      <td>0.036210</td>\n",
       "      <td>0.038745</td>\n",
       "      <td>0.037734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>0.026364</td>\n",
       "      <td>0.028319</td>\n",
       "      <td>0.027695</td>\n",
       "      <td>0.044146</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.028690</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>0.039767</td>\n",
       "      <td>0.036036</td>\n",
       "      <td>0.028251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078441</td>\n",
       "      <td>0.076473</td>\n",
       "      <td>0.076291</td>\n",
       "      <td>0.073755</td>\n",
       "      <td>0.087230</td>\n",
       "      <td>0.089535</td>\n",
       "      <td>0.098972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2824 rows × 403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          2000      2020      2040      2060      2080      2100      2120   \n",
       "0     0.021271  0.021774  0.025388  0.021310  0.022024  0.029203  0.028496  \\\n",
       "1     0.008401  0.007471  0.007531  0.007448  0.007080  0.006454  0.006307   \n",
       "2     0.021248  0.020157  0.021281  0.040733  0.027967  0.025514  0.025027   \n",
       "3     0.019755  0.033714  0.025336  0.036465  0.024422  0.020777  0.022242   \n",
       "4     0.010368  0.010467  0.007812  0.007254  0.008660  0.012023  0.014619   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2819  0.047280  0.045602  0.046357  0.062193  0.052936  0.050927  0.049359   \n",
       "2820  0.121892  0.118875  0.135706  0.156375  0.114842  0.114014  0.110345   \n",
       "2821  0.039517  0.046617  0.045379  0.090256  0.060707  0.055033  0.059977   \n",
       "2822  0.005814  0.004390  0.004179  0.004032  0.004289  0.004521  0.005645   \n",
       "2823  0.026364  0.028319  0.027695  0.044146  0.033335  0.028690  0.031532   \n",
       "\n",
       "          2140      2160      2180  ...      9860      9880      9900   \n",
       "0     0.030084  0.024553  0.040691  ...  0.037734  0.034542  0.031264  \\\n",
       "1     0.014959  0.006481  0.005659  ...  0.015979  0.015110  0.014384   \n",
       "2     0.029584  0.026714  0.021601  ...  0.023793  0.020226  0.022981   \n",
       "3     0.026822  0.031641  0.028074  ...  0.040163  0.037922  0.043811   \n",
       "4     0.056800  0.014732  0.012319  ...  0.142658  0.124189  0.146476   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2819  0.061550  0.053316  0.048646  ...  0.020823  0.036683  0.025691   \n",
       "2820  0.131316  0.135759  0.122672  ...  0.062531  0.074468  0.067012   \n",
       "2821  0.072631  0.064026  0.050019  ...  0.009032  0.008215  0.005234   \n",
       "2822  0.008377  0.004863  0.005159  ...  0.038374  0.030132  0.027900   \n",
       "2823  0.039767  0.036036  0.028251  ...  0.078441  0.076473  0.076291   \n",
       "\n",
       "          9920      9940      9960      9980  Oxacillin  Clindamycin   \n",
       "0     0.027489  0.035240  0.035080  0.034169        0.0          0.0  \\\n",
       "1     0.016972  0.018075  0.024027  0.025398        0.0          0.0   \n",
       "2     0.023913  0.026685  0.026365  0.026794        0.0          0.0   \n",
       "3     0.045006  0.046522  0.051603  0.051320        0.0          0.0   \n",
       "4     0.148880  0.145308  0.161595  0.200539        0.0          0.0   \n",
       "...        ...       ...       ...       ...        ...          ...   \n",
       "2819  0.022913  0.020591  0.023360  0.021736        0.0          1.0   \n",
       "2820  0.078088  0.075663  0.082759  0.081547        0.0          1.0   \n",
       "2821  0.004677  0.004779  0.004562  0.005416        0.0          0.0   \n",
       "2822  0.032357  0.036210  0.038745  0.037734        1.0          1.0   \n",
       "2823  0.073755  0.087230  0.089535  0.098972        0.0          0.0   \n",
       "\n",
       "      Fusidic acid  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "...            ...  \n",
       "2819           0.0  \n",
       "2820           0.0  \n",
       "2821           0.0  \n",
       "2822           0.0  \n",
       "2823           0.0  \n",
       "\n",
       "[2824 rows x 403 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = \"data/processed/binned/train_s_aureus_driams_bin5.csv\"\n",
    "train_bac = pd.read_csv(train_file)\n",
    "train_bac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2020</th>\n",
       "      <th>2040</th>\n",
       "      <th>2060</th>\n",
       "      <th>2080</th>\n",
       "      <th>2100</th>\n",
       "      <th>2120</th>\n",
       "      <th>2140</th>\n",
       "      <th>2160</th>\n",
       "      <th>2180</th>\n",
       "      <th>...</th>\n",
       "      <th>9860</th>\n",
       "      <th>9880</th>\n",
       "      <th>9900</th>\n",
       "      <th>9920</th>\n",
       "      <th>9940</th>\n",
       "      <th>9960</th>\n",
       "      <th>9980</th>\n",
       "      <th>Oxacillin</th>\n",
       "      <th>Clindamycin</th>\n",
       "      <th>Fusidic acid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040233</td>\n",
       "      <td>0.039182</td>\n",
       "      <td>0.036141</td>\n",
       "      <td>0.055947</td>\n",
       "      <td>0.041588</td>\n",
       "      <td>0.035010</td>\n",
       "      <td>0.040361</td>\n",
       "      <td>0.051716</td>\n",
       "      <td>0.048777</td>\n",
       "      <td>0.042674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244114</td>\n",
       "      <td>0.205781</td>\n",
       "      <td>0.197681</td>\n",
       "      <td>0.205721</td>\n",
       "      <td>0.220389</td>\n",
       "      <td>0.246994</td>\n",
       "      <td>0.252911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.024843</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021589</td>\n",
       "      <td>0.021412</td>\n",
       "      <td>0.023902</td>\n",
       "      <td>0.032218</td>\n",
       "      <td>0.035276</td>\n",
       "      <td>0.041813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029025</td>\n",
       "      <td>0.030321</td>\n",
       "      <td>0.029901</td>\n",
       "      <td>0.049815</td>\n",
       "      <td>0.034221</td>\n",
       "      <td>0.032219</td>\n",
       "      <td>0.034535</td>\n",
       "      <td>0.041287</td>\n",
       "      <td>0.033611</td>\n",
       "      <td>0.028739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068968</td>\n",
       "      <td>0.057153</td>\n",
       "      <td>0.066573</td>\n",
       "      <td>0.073411</td>\n",
       "      <td>0.084606</td>\n",
       "      <td>0.082602</td>\n",
       "      <td>0.081549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016073</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.016210</td>\n",
       "      <td>0.027293</td>\n",
       "      <td>0.022218</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>0.021542</td>\n",
       "      <td>0.034816</td>\n",
       "      <td>0.020937</td>\n",
       "      <td>0.017772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012289</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.005694</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039255</td>\n",
       "      <td>0.031352</td>\n",
       "      <td>0.030771</td>\n",
       "      <td>0.036253</td>\n",
       "      <td>0.036255</td>\n",
       "      <td>0.031406</td>\n",
       "      <td>0.033008</td>\n",
       "      <td>0.042148</td>\n",
       "      <td>0.031658</td>\n",
       "      <td>0.033749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040727</td>\n",
       "      <td>0.044741</td>\n",
       "      <td>0.027953</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.026566</td>\n",
       "      <td>0.026079</td>\n",
       "      <td>0.030433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0.011582</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.013263</td>\n",
       "      <td>0.022686</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014774</td>\n",
       "      <td>0.015089</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>0.016548</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043830</td>\n",
       "      <td>0.037882</td>\n",
       "      <td>0.045471</td>\n",
       "      <td>0.047741</td>\n",
       "      <td>0.053822</td>\n",
       "      <td>0.050840</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>0.017533</td>\n",
       "      <td>0.016964</td>\n",
       "      <td>0.017570</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.020161</td>\n",
       "      <td>0.018173</td>\n",
       "      <td>0.023038</td>\n",
       "      <td>0.039156</td>\n",
       "      <td>0.021047</td>\n",
       "      <td>0.018618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064979</td>\n",
       "      <td>0.037914</td>\n",
       "      <td>0.042551</td>\n",
       "      <td>0.043155</td>\n",
       "      <td>0.047281</td>\n",
       "      <td>0.050678</td>\n",
       "      <td>0.050392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0.046769</td>\n",
       "      <td>0.044975</td>\n",
       "      <td>0.045496</td>\n",
       "      <td>0.084074</td>\n",
       "      <td>0.054947</td>\n",
       "      <td>0.046307</td>\n",
       "      <td>0.052593</td>\n",
       "      <td>0.070593</td>\n",
       "      <td>0.052405</td>\n",
       "      <td>0.039588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099234</td>\n",
       "      <td>0.092673</td>\n",
       "      <td>0.077899</td>\n",
       "      <td>0.081252</td>\n",
       "      <td>0.087370</td>\n",
       "      <td>0.094524</td>\n",
       "      <td>0.089711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>0.011834</td>\n",
       "      <td>0.011044</td>\n",
       "      <td>0.010476</td>\n",
       "      <td>0.012997</td>\n",
       "      <td>0.011621</td>\n",
       "      <td>0.010914</td>\n",
       "      <td>0.010469</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>0.012221</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044459</td>\n",
       "      <td>0.059972</td>\n",
       "      <td>0.057565</td>\n",
       "      <td>0.050916</td>\n",
       "      <td>0.049549</td>\n",
       "      <td>0.054562</td>\n",
       "      <td>0.058033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>0.024310</td>\n",
       "      <td>0.028823</td>\n",
       "      <td>0.028368</td>\n",
       "      <td>0.051949</td>\n",
       "      <td>0.033529</td>\n",
       "      <td>0.031858</td>\n",
       "      <td>0.034168</td>\n",
       "      <td>0.046457</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>0.032232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062584</td>\n",
       "      <td>0.046192</td>\n",
       "      <td>0.046487</td>\n",
       "      <td>0.050059</td>\n",
       "      <td>0.057981</td>\n",
       "      <td>0.059696</td>\n",
       "      <td>0.054378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2000      2020      2040      2060      2080      2100      2120   \n",
       "0    0.040233  0.039182  0.036141  0.055947  0.041588  0.035010  0.040361  \\\n",
       "1    0.001984  0.002287  0.001342  0.001770  0.001454  0.003859  0.004831   \n",
       "2    0.029025  0.030321  0.029901  0.049815  0.034221  0.032219  0.034535   \n",
       "3    0.016073  0.015850  0.016210  0.027293  0.022218  0.018732  0.021542   \n",
       "4    0.039255  0.031352  0.030771  0.036253  0.036255  0.031406  0.033008   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "702  0.011582  0.013723  0.013263  0.022686  0.014900  0.014774  0.015089   \n",
       "703  0.017533  0.016964  0.017570  0.025974  0.020161  0.018173  0.023038   \n",
       "704  0.046769  0.044975  0.045496  0.084074  0.054947  0.046307  0.052593   \n",
       "705  0.011834  0.011044  0.010476  0.012997  0.011621  0.010914  0.010469   \n",
       "706  0.024310  0.028823  0.028368  0.051949  0.033529  0.031858  0.034168   \n",
       "\n",
       "         2140      2160      2180  ...      9860      9880      9900   \n",
       "0    0.051716  0.048777  0.042674  ...  0.244114  0.205781  0.197681  \\\n",
       "1    0.024843  0.004303  0.002493  ...  0.021739  0.021589  0.021412   \n",
       "2    0.041287  0.033611  0.028739  ...  0.068968  0.057153  0.066573   \n",
       "3    0.034816  0.020937  0.017772  ...  0.012289  0.006948  0.005129   \n",
       "4    0.042148  0.031658  0.033749  ...  0.040727  0.044741  0.027953   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "702  0.017437  0.016548  0.020700  ...  0.043830  0.037882  0.045471   \n",
       "703  0.039156  0.021047  0.018618  ...  0.064979  0.037914  0.042551   \n",
       "704  0.070593  0.052405  0.039588  ...  0.099234  0.092673  0.077899   \n",
       "705  0.013829  0.012221  0.011838  ...  0.044459  0.059972  0.057565   \n",
       "706  0.046457  0.040936  0.032232  ...  0.062584  0.046192  0.046487   \n",
       "\n",
       "         9920      9940      9960      9980  Oxacillin  Clindamycin   \n",
       "0    0.205721  0.220389  0.246994  0.252911        0.0          0.0  \\\n",
       "1    0.023902  0.032218  0.035276  0.041813        0.0          0.0   \n",
       "2    0.073411  0.084606  0.082602  0.081549        0.0          1.0   \n",
       "3    0.005349  0.005630  0.005694  0.005128        0.0          0.0   \n",
       "4    0.025696  0.026566  0.026079  0.030433        0.0          0.0   \n",
       "..        ...       ...       ...       ...        ...          ...   \n",
       "702  0.047741  0.053822  0.050840  0.059200        0.0          0.0   \n",
       "703  0.043155  0.047281  0.050678  0.050392        1.0          0.0   \n",
       "704  0.081252  0.087370  0.094524  0.089711        0.0          0.0   \n",
       "705  0.050916  0.049549  0.054562  0.058033        1.0          0.0   \n",
       "706  0.050059  0.057981  0.059696  0.054378        0.0          0.0   \n",
       "\n",
       "     Fusidic acid  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             1.0  \n",
       "4             0.0  \n",
       "..            ...  \n",
       "702           0.0  \n",
       "703           0.0  \n",
       "704           1.0  \n",
       "705           0.0  \n",
       "706           0.0  \n",
       "\n",
       "[707 rows x 403 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = \"data/processed/binned/test_s_aureus_driams_bin5.csv\"\n",
    "test_bac = pd.read_csv(test_file)\n",
    "test_bac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rXEshQwKQuzR",
    "outputId": "32756288-dd35-49f1-be9b-34bfe433baf7",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_x = train_bac[train_bac.columns.drop(list(train_bac.filter(regex='[^0-9]')))]\n",
    "test_x = test_bac[test_bac.columns.drop(list(test_bac.filter(regex='[^0-9]')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GiCCaGOEQuzS",
    "outputId": "bdc15429-4a19-4332-d59f-dd1c0ce37d88",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "antibiotics = train_bac.columns.drop(train_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_bac[antibiotics]\n",
    "test_y = test_bac[antibiotics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def multilabel_f1_wrapper(true, pred, average=\"weighted\"):\n",
    "    if isinstance(true, list):\n",
    "        true = np.array(true)\n",
    "    elif isinstance(true, pd.DataFrame):\n",
    "        true = true.to_numpy()\n",
    "    if isinstance(pred, list):\n",
    "        pred = np.array(pred)\n",
    "    elif isinstance(true, pd.DataFrame):\n",
    "        pred = pred.to_numpy()\n",
    "    column = 0\n",
    "    total = 0\n",
    "    while column < true[0].size:\n",
    "        total+=f1_score(true[:, column], pred[:, column], average=average)\n",
    "        column+=1\n",
    "    return total/(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def report(true, pred):\n",
    "        \n",
    "    hl = hamming_loss(true, pred)\n",
    "    f1w = multilabel_f1_wrapper(true, pred, \"weighted\")\n",
    "    acc = accuracy_score(true, pred)\n",
    "    \n",
    "    f1u = multilabel_f1_wrapper(true, pred, \"macro\")\n",
    "    f1su = f1_score(true, pred, average=\"macro\")\n",
    "    f1sw = f1_score(true, pred, average=\"weighted\")\n",
    "\n",
    "    \n",
    "    print(\"Main metrics:\")\n",
    "    print(\" Hamming Loss:\", hl)\n",
    "    print(\" Accuracy:\", acc)\n",
    "    print(\" F1 Score (Weighted):\", f1w)\n",
    "    print(\"================================================\")\n",
    "    print(\"Other metrics:\")\n",
    "    print(\" F1 Score (Unweighted):\", f1u)\n",
    "    print(\" F1 Score (sklearn Unweighted):\", f1su)\n",
    "    print(\" F1 Score (sklearn Weighted):\", f1sw)\n",
    "    return hl, acc, f1w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-gP_gv8QuzZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=ClassifierChain(base_estimator=XGBClassifier(base_score=None,\n",
       "                                                                     booster=None,\n",
       "                                                                     callbacks=None,\n",
       "                                                                     colsample_bylevel=None,\n",
       "                                                                     colsample_bynode=None,\n",
       "                                                                     colsample_bytree=None,\n",
       "                                                                     early_stopping_rounds=None,\n",
       "                                                                     enable_categorical=False,\n",
       "                                                                     eval_metric=None,\n",
       "                                                                     feature_types=None,\n",
       "                                                                     gamma=None,\n",
       "                                                                     gpu_id=None,\n",
       "                                                                     grow_policy=None,\n",
       "                                                                     importance_type=None,\n",
       "                                                                     interaction_cons...\n",
       "                             &#x27;base_estimator__objective&#x27;: Categorical(categories=(&#x27;binary:logistic&#x27;,), prior=None),\n",
       "                             &#x27;base_estimator__scale_pos_weight&#x27;: Real(low=1e-06, high=10, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;base_estimator__subsample&#x27;: Real(low=1e-06, high=1, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;base_estimator__tree_method&#x27;: Categorical(categories=(&#x27;exact&#x27;, &#x27;approx&#x27;, &#x27;hist&#x27;), prior=None)},\n",
       "              verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=5,\n",
       "              estimator=ClassifierChain(base_estimator=XGBClassifier(base_score=None,\n",
       "                                                                     booster=None,\n",
       "                                                                     callbacks=None,\n",
       "                                                                     colsample_bylevel=None,\n",
       "                                                                     colsample_bynode=None,\n",
       "                                                                     colsample_bytree=None,\n",
       "                                                                     early_stopping_rounds=None,\n",
       "                                                                     enable_categorical=False,\n",
       "                                                                     eval_metric=None,\n",
       "                                                                     feature_types=None,\n",
       "                                                                     gamma=None,\n",
       "                                                                     gpu_id=None,\n",
       "                                                                     grow_policy=None,\n",
       "                                                                     importance_type=None,\n",
       "                                                                     interaction_cons...\n",
       "                             &#x27;base_estimator__objective&#x27;: Categorical(categories=(&#x27;binary:logistic&#x27;,), prior=None),\n",
       "                             &#x27;base_estimator__scale_pos_weight&#x27;: Real(low=1e-06, high=10, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;base_estimator__subsample&#x27;: Real(low=1e-06, high=1, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;base_estimator__tree_method&#x27;: Categorical(categories=(&#x27;exact&#x27;, &#x27;approx&#x27;, &#x27;hist&#x27;), prior=None)},\n",
       "              verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ClassifierChain</label><div class=\"sk-toggleable__content\"><pre>ClassifierChain(base_estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bynode=None,\n",
       "                                             colsample_bytree=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None,\n",
       "                                             feature_types=None, gamma=None,\n",
       "                                             gpu_id=None, grow_policy=None,\n",
       "                                             importance_type=None,\n",
       "                                             interaction_constraints=None,\n",
       "                                             learning_rate=None, max_bin=None,\n",
       "                                             max_cat_threshold=None,\n",
       "                                             max_cat_to_onehot=None,\n",
       "                                             max_delta_step=None,\n",
       "                                             max_depth=None, max_leaves=None,\n",
       "                                             min_child_weight=None, missing=nan,\n",
       "                                             monotone_constraints=None,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             num_parallel_tree=None,\n",
       "                                             predictor=None, random_state=None, ...),\n",
       "                random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=ClassifierChain(base_estimator=XGBClassifier(base_score=None,\n",
       "                                                                     booster=None,\n",
       "                                                                     callbacks=None,\n",
       "                                                                     colsample_bylevel=None,\n",
       "                                                                     colsample_bynode=None,\n",
       "                                                                     colsample_bytree=None,\n",
       "                                                                     early_stopping_rounds=None,\n",
       "                                                                     enable_categorical=False,\n",
       "                                                                     eval_metric=None,\n",
       "                                                                     feature_types=None,\n",
       "                                                                     gamma=None,\n",
       "                                                                     gpu_id=None,\n",
       "                                                                     grow_policy=None,\n",
       "                                                                     importance_type=None,\n",
       "                                                                     interaction_cons...\n",
       "                             'base_estimator__objective': Categorical(categories=('binary:logistic',), prior=None),\n",
       "                             'base_estimator__scale_pos_weight': Real(low=1e-06, high=10, prior='log-uniform', transform='normalize'),\n",
       "                             'base_estimator__subsample': Real(low=1e-06, high=1, prior='log-uniform', transform='normalize'),\n",
       "                             'base_estimator__tree_method': Categorical(categories=('exact', 'approx', 'hist'), prior=None)},\n",
       "              verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesopt = BayesSearchCV(\n",
    "    ClassifierChain(xgb.XGBClassifier(), random_state=0),\n",
    "    {\n",
    "        \"base_estimator__objective\": Categorical([\"binary:logistic\"]),\n",
    "        \"base_estimator__max_depth\": Integer(1, 10),\n",
    "        \"base_estimator__min_child_weight\": Real(1e-6, 10, prior=\"log-uniform\"),\n",
    "        \"base_estimator__max_delta_step\": Real(1e-6, 10, prior=\"log-uniform\"),\n",
    "        \"base_estimator__subsample\": Real(1e-6, 1, prior=\"log-uniform\"),\n",
    "        \"base_estimator__tree_method\": Categorical([\"exact\", \"approx\", \"hist\"]),\n",
    "        \"base_estimator__scale_pos_weight\": Real(1e-6, 10, prior=\"log-uniform\"),\n",
    "        \"base_estimator__gamma\": Real(1e-6, 10, prior=\"log-uniform\"),\n",
    "        \"base_estimator__eta\": Real(1e-6, 1, prior=\"log-uniform\")\n",
    "    },\n",
    "    n_iter=250,\n",
    "    cv=5,\n",
    "    random_state=0,\n",
    "    n_jobs=10,\n",
    "    n_points=2,\n",
    "    scoring=make_scorer(multilabel_f1_wrapper),\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "bayesopt.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best iteration: 242\n",
      "Split scores:\n",
      " 0 0.8485167786564469\n",
      " 1 0.8616573057610184\n",
      " 2 0.8509100794256234\n",
      " 3 0.8552151198095618\n",
      " 4 0.857133845686513\n",
      "Mean score: 0.8546866258678326\n",
      "Best parameter combination found: OrderedDict([('base_estimator__eta', 1.0), ('base_estimator__gamma', 1e-06), ('base_estimator__max_delta_step', 0.7910985489927498), ('base_estimator__max_depth', 10), ('base_estimator__min_child_weight', 0.07488040746686085), ('base_estimator__objective', 'binary:logistic'), ('base_estimator__scale_pos_weight', 1.1587577248521648), ('base_estimator__subsample', 1.0), ('base_estimator__tree_method', 'exact')])\n"
     ]
    }
   ],
   "source": [
    "best_iteration = 0\n",
    "for i in range(0, 250):\n",
    "    if bayesopt.cv_results_[\"mean_test_score\"][i] == bayesopt.best_score_:\n",
    "        best_iteration = i\n",
    "print(\"Best iteration:\", best_iteration)\n",
    "print(\"Split scores:\")\n",
    "for i in range(0, 5):\n",
    "    print(\"\", i, bayesopt.cv_results_[\"split\"+str(i)+\"_test_score\"][best_iteration])\n",
    "    \n",
    "print(\"Mean score:\", bayesopt.best_score_)\n",
    "print(\"Best parameter combination found:\", bayesopt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"xgb_s_aureus_raw_bin5.joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_s_aureus_raw_bin20.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(bayesopt.best_estimator_, model_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y) \n",
    "pred = model.predict(test_x)\n",
    "model_hl, model_acc, model_f1 = report(test_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(antibiotics), figsize=(len(antibiotics)*5, 5))\n",
    "fig.supxlabel(\"Predicted Label\")\n",
    "fig.supylabel(\"True Label\")\n",
    "\n",
    "cm_svm_c = multilabel_confusion_matrix(test_y, (pred > 0.5))\n",
    "\n",
    "for i in range(len(antibiotics)):\n",
    "  sns.heatmap(ax=axes[i], data=cm_svm_c[i], annot=True, fmt='d', cbar=None, cmap=\"Blues\", xticklabels=[\"S\", \"R\"], yticklabels=[\"S\", \"R\"]).set(title=antibiotics[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = model.predict_proba(test_x)\n",
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for antibiotic in range(len(antibiotics)):\n",
    "    count_tp = 0\n",
    "    count_tn = 0\n",
    "    count_fp = 0\n",
    "    count_fn = 0\n",
    "    sum_tp = 0\n",
    "    sum_tn = 0\n",
    "    sum_fp = 0\n",
    "    sum_fn = 0\n",
    "    for i in range(len(proba[:, antibiotic])):\n",
    "        disc_pred = int(proba[i, antibiotic] > 0.5)\n",
    "        if disc_pred == 1:\n",
    "            if disc_pred == test_y.iloc[i, antibiotic]:\n",
    "                count_tp += 1\n",
    "                sum_tp += proba[i, antibiotic]\n",
    "            else:\n",
    "                count_fp += 1\n",
    "                sum_fp += proba[i, antibiotic]\n",
    "        else:\n",
    "            if disc_pred == test_y.iloc[i, antibiotic]:\n",
    "                count_tn += 1\n",
    "                sum_tn += proba[i, antibiotic]\n",
    "            else:\n",
    "                count_fn += 1\n",
    "                sum_fn += proba[i, antibiotic]\n",
    "    print(\"Results for antibiotic\", antibiotics[antibiotic])\n",
    "    if count_tp == 0:\n",
    "        print(\" Mean TP: None\")\n",
    "    else: \n",
    "        print(\" Mean TP:\", sum_tp/count_tp)\n",
    "    if count_tn == 0:\n",
    "        print(\" Mean TN: None\")\n",
    "    else: \n",
    "        print(\" Mean TN:\", sum_tn/count_tn)\n",
    "    if count_fp == 0:\n",
    "        print(\" Mean FP: None\")\n",
    "    else: \n",
    "        print(\" Mean FP:\", sum_fp/count_fp)\n",
    "    if count_fn == 0:\n",
    "        print(\" Mean FN: None\")\n",
    "    else: \n",
    "        print(\" Mean FN:\", sum_fn/count_fn)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
