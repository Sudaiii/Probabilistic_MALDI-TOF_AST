{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/castudil/bacteria-multi-label/blob/main/multilabel_bac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKUeIuZcpHUl"
   },
   "source": [
    "Libraries used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bzVprbfpWSLa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 16:03:42.059685: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-12 16:03:43.517885: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-12 16:03:43.517946: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-12 16:03:43.582324: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-12 16:03:43.883517: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-12 16:03:47.107366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (f1_score, multilabel_confusion_matrix,\n",
    "                             accuracy_score, hamming_loss, jaccard_score, make_scorer)\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import keras_tuner as kt\n",
    "import keras\n",
    "\n",
    "from joblib import dump, load\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "nQsWnulDWdDD",
    "outputId": "6f97687c-b560-4e34-fd8b-9c3ef7aeb0c7",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>...</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>Oxacillin</th>\n",
       "      <th>Clindamycin</th>\n",
       "      <th>Fusidic acid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018721</td>\n",
       "      <td>0.016147</td>\n",
       "      <td>0.016983</td>\n",
       "      <td>0.021218</td>\n",
       "      <td>0.020846</td>\n",
       "      <td>0.019784</td>\n",
       "      <td>0.019405</td>\n",
       "      <td>0.023356</td>\n",
       "      <td>0.026224</td>\n",
       "      <td>0.026569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037966</td>\n",
       "      <td>0.030364</td>\n",
       "      <td>0.037545</td>\n",
       "      <td>0.040851</td>\n",
       "      <td>0.034176</td>\n",
       "      <td>0.046110</td>\n",
       "      <td>0.025638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.009539</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>0.008314</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.008923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014496</td>\n",
       "      <td>0.024966</td>\n",
       "      <td>0.027437</td>\n",
       "      <td>0.026541</td>\n",
       "      <td>0.022940</td>\n",
       "      <td>0.020572</td>\n",
       "      <td>0.032504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022354</td>\n",
       "      <td>0.020220</td>\n",
       "      <td>0.020910</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.021436</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>0.020229</td>\n",
       "      <td>0.018818</td>\n",
       "      <td>0.018637</td>\n",
       "      <td>0.018815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024620</td>\n",
       "      <td>0.022942</td>\n",
       "      <td>0.026715</td>\n",
       "      <td>0.032045</td>\n",
       "      <td>0.030431</td>\n",
       "      <td>0.029085</td>\n",
       "      <td>0.013117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017619</td>\n",
       "      <td>0.016073</td>\n",
       "      <td>0.016407</td>\n",
       "      <td>0.018011</td>\n",
       "      <td>0.019364</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.017607</td>\n",
       "      <td>0.019116</td>\n",
       "      <td>0.023623</td>\n",
       "      <td>0.024492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051312</td>\n",
       "      <td>0.047458</td>\n",
       "      <td>0.049338</td>\n",
       "      <td>0.055039</td>\n",
       "      <td>0.054541</td>\n",
       "      <td>0.058643</td>\n",
       "      <td>0.058919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>0.006753</td>\n",
       "      <td>0.006657</td>\n",
       "      <td>0.010107</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>0.008134</td>\n",
       "      <td>0.006513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236769</td>\n",
       "      <td>0.217499</td>\n",
       "      <td>0.187244</td>\n",
       "      <td>0.216243</td>\n",
       "      <td>0.221910</td>\n",
       "      <td>0.226531</td>\n",
       "      <td>0.221965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>0.056616</td>\n",
       "      <td>0.039011</td>\n",
       "      <td>0.040380</td>\n",
       "      <td>0.048517</td>\n",
       "      <td>0.050865</td>\n",
       "      <td>0.047771</td>\n",
       "      <td>0.049312</td>\n",
       "      <td>0.048257</td>\n",
       "      <td>0.049417</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021169</td>\n",
       "      <td>0.023617</td>\n",
       "      <td>0.033694</td>\n",
       "      <td>0.021037</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>0.125837</td>\n",
       "      <td>0.107712</td>\n",
       "      <td>0.109186</td>\n",
       "      <td>0.107613</td>\n",
       "      <td>0.109855</td>\n",
       "      <td>0.105060</td>\n",
       "      <td>0.099640</td>\n",
       "      <td>0.104169</td>\n",
       "      <td>0.120303</td>\n",
       "      <td>0.125067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082375</td>\n",
       "      <td>0.083446</td>\n",
       "      <td>0.096510</td>\n",
       "      <td>0.084883</td>\n",
       "      <td>0.092228</td>\n",
       "      <td>0.085599</td>\n",
       "      <td>0.042142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035603</td>\n",
       "      <td>0.039994</td>\n",
       "      <td>0.042372</td>\n",
       "      <td>0.046666</td>\n",
       "      <td>0.045781</td>\n",
       "      <td>0.043914</td>\n",
       "      <td>0.039875</td>\n",
       "      <td>0.037170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006903</td>\n",
       "      <td>0.008322</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>0.005443</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.005588</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>0.004853</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049241</td>\n",
       "      <td>0.039586</td>\n",
       "      <td>0.050542</td>\n",
       "      <td>0.039139</td>\n",
       "      <td>0.046816</td>\n",
       "      <td>0.043036</td>\n",
       "      <td>0.037402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>0.026184</td>\n",
       "      <td>0.022810</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.020464</td>\n",
       "      <td>0.026694</td>\n",
       "      <td>0.024624</td>\n",
       "      <td>0.025140</td>\n",
       "      <td>0.026609</td>\n",
       "      <td>0.024203</td>\n",
       "      <td>0.020953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090198</td>\n",
       "      <td>0.101889</td>\n",
       "      <td>0.105174</td>\n",
       "      <td>0.122065</td>\n",
       "      <td>0.095740</td>\n",
       "      <td>0.082289</td>\n",
       "      <td>0.081714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2824 rows × 8003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          2000      2001      2002      2003      2004      2005      2006   \n",
       "0     0.018721  0.016147  0.016983  0.021218  0.020846  0.019784  0.019405  \\\n",
       "1     0.009001  0.007475  0.006874  0.008575  0.009539  0.007894  0.008314   \n",
       "2     0.022354  0.020220  0.020910  0.024631  0.021436  0.021197  0.020229   \n",
       "3     0.017619  0.016073  0.016407  0.018011  0.019364  0.018950  0.017607   \n",
       "4     0.008264  0.008229  0.006753  0.006657  0.010107  0.007039  0.008250   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2819  0.056616  0.039011  0.040380  0.048517  0.050865  0.047771  0.049312   \n",
       "2820  0.125837  0.107712  0.109186  0.107613  0.109855  0.105060  0.099640   \n",
       "2821  0.000000  0.000000  0.035603  0.039994  0.042372  0.046666  0.045781   \n",
       "2822  0.005443  0.005998  0.003670  0.005588  0.006124  0.005019  0.004853   \n",
       "2823  0.026184  0.022810  0.023200  0.020464  0.026694  0.024624  0.025140   \n",
       "\n",
       "          2007      2008      2009  ...      9993      9994      9995   \n",
       "0     0.023356  0.026224  0.026569  ...  0.037966  0.030364  0.037545  \\\n",
       "1     0.008013  0.008664  0.008923  ...  0.014496  0.024966  0.027437   \n",
       "2     0.018818  0.018637  0.018815  ...  0.024620  0.022942  0.026715   \n",
       "3     0.019116  0.023623  0.024492  ...  0.051312  0.047458  0.049338   \n",
       "4     0.010670  0.008134  0.006513  ...  0.236769  0.217499  0.187244   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2819  0.048257  0.049417  0.049000  ...  0.021169  0.023617  0.033694   \n",
       "2820  0.104169  0.120303  0.125067  ...  0.082375  0.083446  0.096510   \n",
       "2821  0.043914  0.039875  0.037170  ...  0.006903  0.008322  0.011071   \n",
       "2822  0.005400  0.004169  0.005151  ...  0.049241  0.039586  0.050542   \n",
       "2823  0.026609  0.024203  0.020953  ...  0.090198  0.101889  0.105174   \n",
       "\n",
       "          9996      9997      9998      9999  Oxacillin  Clindamycin   \n",
       "0     0.040851  0.034176  0.046110  0.025638        0.0          0.0  \\\n",
       "1     0.026541  0.022940  0.020572  0.032504        0.0          0.0   \n",
       "2     0.032045  0.030431  0.029085  0.013117        0.0          0.0   \n",
       "3     0.055039  0.054541  0.058643  0.058919        0.0          0.0   \n",
       "4     0.216243  0.221910  0.226531  0.221965        0.0          0.0   \n",
       "...        ...       ...       ...       ...        ...          ...   \n",
       "2819  0.021037  0.018727  0.010641  0.009238        0.0          1.0   \n",
       "2820  0.084883  0.092228  0.085599  0.042142        0.0          1.0   \n",
       "2821  0.010274  0.004682  0.003547  0.001744        0.0          0.0   \n",
       "2822  0.039139  0.046816  0.043036  0.037402        1.0          1.0   \n",
       "2823  0.122065  0.095740  0.082289  0.081714        0.0          0.0   \n",
       "\n",
       "      Fusidic acid  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "...            ...  \n",
       "2819           0.0  \n",
       "2820           0.0  \n",
       "2821           0.0  \n",
       "2822           0.0  \n",
       "2823           0.0  \n",
       "\n",
       "[2824 rows x 8003 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = \"data/processed/raw/train_s_aureus_driams.csv\"\n",
    "train_bac = pd.read_csv(train_file)\n",
    "train_bac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>...</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>Oxacillin</th>\n",
       "      <th>Clindamycin</th>\n",
       "      <th>Fusidic acid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044453</td>\n",
       "      <td>0.032486</td>\n",
       "      <td>0.032540</td>\n",
       "      <td>0.034223</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>0.039503</td>\n",
       "      <td>0.031378</td>\n",
       "      <td>0.035506</td>\n",
       "      <td>0.037688</td>\n",
       "      <td>0.035658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247814</td>\n",
       "      <td>0.263833</td>\n",
       "      <td>0.279904</td>\n",
       "      <td>0.264432</td>\n",
       "      <td>0.241573</td>\n",
       "      <td>0.266020</td>\n",
       "      <td>0.231517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033364</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.066426</td>\n",
       "      <td>0.057485</td>\n",
       "      <td>0.052903</td>\n",
       "      <td>0.050839</td>\n",
       "      <td>0.036631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026184</td>\n",
       "      <td>0.026459</td>\n",
       "      <td>0.025393</td>\n",
       "      <td>0.028609</td>\n",
       "      <td>0.031314</td>\n",
       "      <td>0.031739</td>\n",
       "      <td>0.033337</td>\n",
       "      <td>0.028051</td>\n",
       "      <td>0.028047</td>\n",
       "      <td>0.028978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086746</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.094103</td>\n",
       "      <td>0.080969</td>\n",
       "      <td>0.073970</td>\n",
       "      <td>0.069047</td>\n",
       "      <td>0.070988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015010</td>\n",
       "      <td>0.017782</td>\n",
       "      <td>0.014582</td>\n",
       "      <td>0.015084</td>\n",
       "      <td>0.018046</td>\n",
       "      <td>0.014461</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.018769</td>\n",
       "      <td>0.018272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.007583</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060499</td>\n",
       "      <td>0.043034</td>\n",
       "      <td>0.030296</td>\n",
       "      <td>0.032635</td>\n",
       "      <td>0.031272</td>\n",
       "      <td>0.032762</td>\n",
       "      <td>0.031154</td>\n",
       "      <td>0.030382</td>\n",
       "      <td>0.030233</td>\n",
       "      <td>0.029438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029452</td>\n",
       "      <td>0.033288</td>\n",
       "      <td>0.039230</td>\n",
       "      <td>0.046477</td>\n",
       "      <td>0.037219</td>\n",
       "      <td>0.022227</td>\n",
       "      <td>0.019920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0.013092</td>\n",
       "      <td>0.011730</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>0.013513</td>\n",
       "      <td>0.015317</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>0.013338</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050851</td>\n",
       "      <td>0.046334</td>\n",
       "      <td>0.042840</td>\n",
       "      <td>0.061644</td>\n",
       "      <td>0.066948</td>\n",
       "      <td>0.061007</td>\n",
       "      <td>0.056178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>0.021222</td>\n",
       "      <td>0.015896</td>\n",
       "      <td>0.015512</td>\n",
       "      <td>0.017995</td>\n",
       "      <td>0.018663</td>\n",
       "      <td>0.019427</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.014589</td>\n",
       "      <td>0.016765</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047285</td>\n",
       "      <td>0.056455</td>\n",
       "      <td>0.058002</td>\n",
       "      <td>0.055528</td>\n",
       "      <td>0.043539</td>\n",
       "      <td>0.039962</td>\n",
       "      <td>0.034761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0.045613</td>\n",
       "      <td>0.041040</td>\n",
       "      <td>0.046177</td>\n",
       "      <td>0.050216</td>\n",
       "      <td>0.046525</td>\n",
       "      <td>0.048843</td>\n",
       "      <td>0.045920</td>\n",
       "      <td>0.044283</td>\n",
       "      <td>0.043983</td>\n",
       "      <td>0.046330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104234</td>\n",
       "      <td>0.094692</td>\n",
       "      <td>0.090012</td>\n",
       "      <td>0.096624</td>\n",
       "      <td>0.092228</td>\n",
       "      <td>0.100024</td>\n",
       "      <td>0.043682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>0.015193</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>0.010877</td>\n",
       "      <td>0.009975</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.010783</td>\n",
       "      <td>0.013170</td>\n",
       "      <td>0.014157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051772</td>\n",
       "      <td>0.058255</td>\n",
       "      <td>0.074609</td>\n",
       "      <td>0.068249</td>\n",
       "      <td>0.049157</td>\n",
       "      <td>0.070229</td>\n",
       "      <td>0.043615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>0.025453</td>\n",
       "      <td>0.022209</td>\n",
       "      <td>0.022442</td>\n",
       "      <td>0.025181</td>\n",
       "      <td>0.025069</td>\n",
       "      <td>0.025761</td>\n",
       "      <td>0.022690</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.022596</td>\n",
       "      <td>0.025572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052692</td>\n",
       "      <td>0.061853</td>\n",
       "      <td>0.048375</td>\n",
       "      <td>0.060665</td>\n",
       "      <td>0.043305</td>\n",
       "      <td>0.041617</td>\n",
       "      <td>0.048284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>707 rows × 8003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2000      2001      2002      2003      2004      2005      2006   \n",
       "0    0.044453  0.032486  0.032540  0.034223  0.037528  0.039503  0.031378  \\\n",
       "1    0.004318  0.001881  0.001274  0.000902  0.000892  0.000049  0.002188   \n",
       "2    0.026184  0.026459  0.025393  0.028609  0.031314  0.031739  0.033337   \n",
       "3    0.000000  0.015010  0.017782  0.014582  0.015084  0.018046  0.014461   \n",
       "4    0.060499  0.043034  0.030296  0.032635  0.031272  0.032762  0.031154   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "702  0.013092  0.011730  0.009902  0.013513  0.015317  0.011370  0.013338   \n",
       "703  0.021222  0.015896  0.015512  0.017995  0.018663  0.019427  0.018667   \n",
       "704  0.045613  0.041040  0.046177  0.050216  0.046525  0.048843  0.045920   \n",
       "705  0.015193  0.011922  0.010877  0.009975  0.010474  0.012171  0.010417   \n",
       "706  0.025453  0.022209  0.022442  0.025181  0.025069  0.025761  0.022690   \n",
       "\n",
       "         2007      2008      2009  ...      9993      9994      9995   \n",
       "0    0.035506  0.037688  0.035658  ...  0.247814  0.263833  0.279904  \\\n",
       "1    0.002001  0.003081  0.003384  ...  0.033364  0.042735  0.066426   \n",
       "2    0.028051  0.028047  0.028978  ...  0.086746  0.087719  0.094103   \n",
       "3    0.014400  0.018769  0.018272  ...  0.005062  0.006748  0.004573   \n",
       "4    0.030382  0.030233  0.029438  ...  0.029452  0.033288  0.039230   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "702  0.010117  0.010994  0.009222  ...  0.050851  0.046334  0.042840   \n",
       "703  0.014589  0.016765  0.015071  ...  0.047285  0.056455  0.058002   \n",
       "704  0.044283  0.043983  0.046330  ...  0.104234  0.094692  0.090012   \n",
       "705  0.010783  0.013170  0.014157  ...  0.051772  0.058255  0.074609   \n",
       "706  0.024250  0.022596  0.025572  ...  0.052692  0.061853  0.048375   \n",
       "\n",
       "         9996      9997      9998      9999  Oxacillin  Clindamycin   \n",
       "0    0.264432  0.241573  0.266020  0.231517        0.0          0.0  \\\n",
       "1    0.057485  0.052903  0.050839  0.036631        0.0          0.0   \n",
       "2    0.080969  0.073970  0.069047  0.070988        0.0          1.0   \n",
       "3    0.007583  0.008427  0.004729  0.002394        0.0          0.0   \n",
       "4    0.046477  0.037219  0.022227  0.019920        0.0          0.0   \n",
       "..        ...       ...       ...       ...        ...          ...   \n",
       "702  0.061644  0.066948  0.061007  0.056178        0.0          0.0   \n",
       "703  0.055528  0.043539  0.039962  0.034761        1.0          0.0   \n",
       "704  0.096624  0.092228  0.100024  0.043682        0.0          0.0   \n",
       "705  0.068249  0.049157  0.070229  0.043615        1.0          0.0   \n",
       "706  0.060665  0.043305  0.041617  0.048284        0.0          0.0   \n",
       "\n",
       "     Fusidic acid  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             1.0  \n",
       "4             0.0  \n",
       "..            ...  \n",
       "702           0.0  \n",
       "703           0.0  \n",
       "704           1.0  \n",
       "705           0.0  \n",
       "706           0.0  \n",
       "\n",
       "[707 rows x 8003 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = \"data/processed/raw/test_s_aureus_driams.csv\"\n",
    "test_bac = pd.read_csv(test_file)\n",
    "test_bac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rXEshQwKQuzR",
    "outputId": "32756288-dd35-49f1-be9b-34bfe433baf7",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_x = train_bac[train_bac.columns.drop(list(train_bac.filter(regex='[^0-9]')))]\n",
    "test_x = test_bac[test_bac.columns.drop(list(test_bac.filter(regex='[^0-9]')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GiCCaGOEQuzS",
    "outputId": "bdc15429-4a19-4332-d59f-dd1c0ce37d88",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "antibiotics = train_bac.columns.drop(train_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_bac[antibiotics]\n",
    "test_y = test_bac[antibiotics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/features/s_aureus_driams_selected_features.txt\") as file:\n",
    "    selected_features = file.read().split(\",\")\n",
    "selected_features.pop()\n",
    "\n",
    "train_x = train_x[selected_features]\n",
    "test_x = test_x[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_f1_wrapper(true, pred, average=\"weighted\"):\n",
    "    if isinstance(true, list):\n",
    "        true = np.array(true)\n",
    "    elif isinstance(true, pd.DataFrame):\n",
    "        true = true.to_numpy()\n",
    "    if isinstance(pred, list):\n",
    "        pred = np.array(pred)\n",
    "    elif isinstance(true, pd.DataFrame):\n",
    "        pred = pred.to_numpy()\n",
    "    column = 0\n",
    "    total = 0\n",
    "    while column < true[0].size:\n",
    "        total+=f1_score(true[:, column], pred[:, column], average=average)\n",
    "        column+=1\n",
    "    return total/(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(true, pred):\n",
    "        \n",
    "    hl = hamming_loss(true, pred)\n",
    "    f1w = multilabel_f1_wrapper(true, pred, \"weighted\")\n",
    "    acc = accuracy_score(true, pred)\n",
    "    \n",
    "    f1u = multilabel_f1_wrapper(true, pred, \"macro\")\n",
    "    f1su = f1_score(true, pred, average=\"macro\")\n",
    "    f1sw = f1_score(true, pred, average=\"weighted\")\n",
    "\n",
    "    \n",
    "    print(\"Main metrics:\")\n",
    "    print(\" Hamming Loss:\", hl)\n",
    "    print(\" Accuracy:\", acc)\n",
    "    print(\" F1 Score (Weighted):\", f1w)\n",
    "    print(\"================================================\")\n",
    "    print(\"Other metrics:\")\n",
    "    print(\" F1 Score (Unweighted):\", f1u)\n",
    "    print(\" F1 Score (sklearn Unweighted):\", f1su)\n",
    "    print(\" F1 Score (sklearn Weighted):\", f1sw)\n",
    "    return hl, acc, f1w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseBacModel(Model):\n",
    "  def __init__(self, input_dim, output_dim, units):\n",
    "    super().__init__()\n",
    "    self.d1 = Dense(units, input_dim=input_dim, kernel_initializer=\"he_uniform\", activation=\"relu\")\n",
    "    self.d2 = Dense(output_dim, activation='sigmoid')\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(x, y):\n",
    "    results = list()\n",
    "    \n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "    \n",
    "    np_x = x.to_numpy()\n",
    "    np_y = y.to_numpy()\n",
    "    \n",
    "    for train_i, validation_i in cv.split(np_x):\n",
    "        input_dim  = len(x.columns)\n",
    "        output_dim = len(y.columns)\n",
    "        model = BaseBacModel(input_dim, output_dim, 512)\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "        \n",
    "        train_x = np_x[train_i]\n",
    "        train_y = np_y[train_i]\n",
    "        validation_x = np_x[validation_i]\n",
    "        validation_y = np_y[validation_i]\n",
    "\n",
    "        model.fit(train_x, train_y, verbose=1, epochs=100)\n",
    "\n",
    "        pred = model.predict(validation_x)\n",
    "        pred = pred.round()\n",
    "        \n",
    "        hl, acc, f1w = report(validation_y, pred)\n",
    "\n",
    "        results.append(f1w)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 16:03:57.690060: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-12-12 16:03:57.690119: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: dslab\n",
      "2023-12-12 16:03:57.690129: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: dslab\n",
      "2023-12-12 16:03:57.690325: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 470.199.2\n",
      "2023-12-12 16:03:57.690357: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 470.199.2\n",
      "2023-12-12 16:03:57.690365: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 470.199.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 1s 3ms/step - loss: 0.4572\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3848\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3569\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3435\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3372\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3308\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3283\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3232\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3186\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3162\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3119\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3096\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3058\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3040\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3030\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2982\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2972\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2963\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2947\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2904\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2882\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2886\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2855\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2859\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2825\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2805\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2788\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2751\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2758\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2737\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2742\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2712\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2695\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2688\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2673\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2633\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2631\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2624\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2615\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2601\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2587\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2584\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2568\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2559\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2530\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2509\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2502\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2507\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2469\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2475\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2456\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2448\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2443\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2417\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2407\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2414\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2377\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2400\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2377\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2360\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2348\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2347\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2333\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2314\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2306\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2293\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2286\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2276\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2267\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2267\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2297\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2253\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2228\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2225\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2206\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2208\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2212\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2184\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2181\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2162\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2146\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2138\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2149\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2149\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2114\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2099\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2101\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2114\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2083\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2083\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2073\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2060\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2062\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2055\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2032\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2030\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2032\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2029\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2033\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1991\n",
      "18/18 [==============================] - 0s 745us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.09734513274336283\n",
      " Accuracy: 0.7433628318584071\n",
      " F1 Score (Weighted): 0.886130412910842\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.6747959092883141\n",
      " F1 Score (sklearn Unweighted): 0.40432208026260735\n",
      " F1 Score (sklearn Weighted): 0.5024867163402988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.4606\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3823\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3570\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3453\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.3371\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.3330\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3290\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3230\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3217\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3148\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3128\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3090\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.3078\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3047\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3018\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3015\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2968\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2961\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2934\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2912\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2895\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2899\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2845\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2845\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2808\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2792\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2777\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2779\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2761\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2745\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2723\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2708\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2701\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2673\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2670\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2645\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2637\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2606\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2585\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2590\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2562\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2579\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2544\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2534\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2522\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2518\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2513\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2484\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2482\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2450\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2447\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2444\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2412\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2424\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2418\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2391\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2386\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2363\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2343\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2357\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2333\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2311\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2302\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2308\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2319\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2287\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2276\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2267\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2250\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2248\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2229\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2212\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2214\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2193\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2203\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2168\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2192\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2187\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2153\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2155\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2157\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2114\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2125\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2103\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2114\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2099\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2098\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2085\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2057\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2065\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2044\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2039\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2033\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2043\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2023\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2005\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2001\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1989\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2003\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1972\n",
      "18/18 [==============================] - 0s 801us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.10206489675516224\n",
      " Accuracy: 0.736283185840708\n",
      " F1 Score (Weighted): 0.8800419848643405\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.6904303465991785\n",
      " F1 Score (sklearn Unweighted): 0.43859484677574834\n",
      " F1 Score (sklearn Weighted): 0.5093188036172748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.4539\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3764\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3488\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3380\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3307\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3249\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3199\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3207\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3120\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3086\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3054\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3028\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3009\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2973\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2945\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2932\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2902\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2901\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2859\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2849\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2801\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2803\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2786\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2756\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2739\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2723\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2709\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2683\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2683\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2655\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2640\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2624\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2614\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2580\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2602\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2566\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2559\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2548\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2532\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2517\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2495\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2491\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2475\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2458\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2439\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2442\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2417\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2403\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2425\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2388\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2373\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2355\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2352\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2340\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2339\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2323\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2289\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2297\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2287\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2273\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2274\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2252\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2241\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2242\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2208\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2207\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2187\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2172\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2187\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2163\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2143\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2175\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2148\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2103\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2120\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2088\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2113\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2088\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2071\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2054\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2058\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2054\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2052\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2027\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2015\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2012\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1995\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1994\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1976\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1963\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1948\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1961\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1945\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1939\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1932\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1949\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1915\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1933\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1892\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1888\n",
      "18/18 [==============================] - 0s 756us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.11858407079646018\n",
      " Accuracy: 0.7026548672566372\n",
      " F1 Score (Weighted): 0.856611204697506\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.6414960800989623\n",
      " F1 Score (sklearn Unweighted): 0.3508957181166023\n",
      " F1 Score (sklearn Weighted): 0.4336087913175136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.4610\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3920\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3646\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3520\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3435\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3410\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3334\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3284\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3247\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3205\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3192\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3150\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3104\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3081\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.3034\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.3014\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2999\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2998\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2951\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2926\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2917\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2889\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2889\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2855\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2835\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2819\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2807\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2778\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2756\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2740\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2727\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2711\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2701\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2679\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2667\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2656\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2640\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2617\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2653\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2597\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2603\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2587\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2551\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2543\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2520\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2501\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2499\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2489\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2462\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2434\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2436\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2410\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2413\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2393\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2390\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2382\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2368\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2430\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2342\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2337\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2335\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2318\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2289\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2272\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2276\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2261\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2269\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2251\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2223\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2228\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2213\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2200\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2184\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2195\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2211\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2187\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2167\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2134\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2133\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2130\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2100\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2103\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2085\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2078\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2073\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2082\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2101\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2044\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2061\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2031\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2031\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2024\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2002\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1992\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1995\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1989\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1974\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1966\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1940\n",
      "18/18 [==============================] - 0s 754us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.09321533923303835\n",
      " Accuracy: 0.7557522123893805\n",
      " F1 Score (Weighted): 0.8925444105143705\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.6570975085934868\n",
      " F1 Score (sklearn Unweighted): 0.36632996632996634\n",
      " F1 Score (sklearn Weighted): 0.4472420540483367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.4574\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3866\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.3561\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3448\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3370\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3329\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3271\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3234\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3187\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3143\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3139\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3088\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3061\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3015\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3017\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2986\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2952\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2926\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2933\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2889\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2874\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2845\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2823\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2810\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2788\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2792\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2765\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2731\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2716\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2710\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2686\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2688\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2659\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2647\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2630\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2612\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2609\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2596\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2570\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2564\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2540\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2517\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2504\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2500\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2485\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2452\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2464\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2435\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2421\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2413\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2391\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2384\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2384\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2378\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2355\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2337\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2345\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2329\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2325\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2302\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2286\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2279\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2280\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2253\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2249\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2247\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2226\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2221\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2198\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2188\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2177\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2175\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2159\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2147\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2129\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2130\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2130\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2124\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2120\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2097\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2078\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2076\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2081\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2039\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2041\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2026\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2022\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2027\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2015\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1997\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1988\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1983\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1974\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1963\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1947\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1944\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1938\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1915\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1948\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1905\n",
      "18/18 [==============================] - 0s 776us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.10874704491725769\n",
      " Accuracy: 0.7145390070921985\n",
      " F1 Score (Weighted): 0.8722915379188297\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.6380672546551942\n",
      " F1 Score (sklearn Unweighted): 0.3381065453283581\n",
      " F1 Score (sklearn Weighted): 0.43930745318426745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.886130412910842,\n",
       " 0.8800419848643405,\n",
       " 0.856611204697506,\n",
       " 0.8925444105143705,\n",
       " 0.8722915379188297]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_train(x, y, model):\n",
    "    results = list()\n",
    "    \n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "    \n",
    "    np_x = x.to_numpy()\n",
    "    np_y = y.to_numpy()\n",
    "    \n",
    "    for train_i, validation_i in cv.split(np_x):\n",
    "        train_x = np_x[train_i]\n",
    "        train_y = np_y[train_i]\n",
    "        validation_x = np_x[validation_i]\n",
    "        validation_y = np_y[validation_i]\n",
    "\n",
    "        model.fit(train_x, train_y, verbose=1, epochs=100)\n",
    "\n",
    "        pred = model.predict(validation_x)\n",
    "        pred = pred.round()\n",
    "        \n",
    "        hl, acc, f1w = report(validation_y, pred)\n",
    "\n",
    "        results.append(f1w)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.4558\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3859\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3578\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3441\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3375\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3309\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3284\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3231\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3184\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3160\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3116\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3089\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3053\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3033\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3026\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2976\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2969\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2957\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2942\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2897\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2874\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2879\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2848\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2855\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2821\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2802\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2784\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2745\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2750\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2731\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2735\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2707\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2688\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2680\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2663\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2625\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2626\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2615\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2608\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2592\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2580\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2577\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2558\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2552\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2522\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2498\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2495\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2494\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2462\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2464\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2451\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2436\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2436\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2406\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2393\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2404\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2367\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2387\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2360\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2347\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2332\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2338\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2320\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2298\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2293\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2274\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2270\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2258\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2250\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2248\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2280\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2235\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2208\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2209\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2190\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2190\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2190\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2165\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2161\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2142\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2126\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2118\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2128\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2126\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2095\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2080\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2078\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2097\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2063\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2066\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2051\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2038\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2036\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2031\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2011\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2008\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2005\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2003\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2012\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1969\n",
      "18/18 [==============================] - 0s 689us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.0967551622418879\n",
      " Accuracy: 0.7433628318584071\n",
      " F1 Score (Weighted): 0.8865277054527382\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.6707211425136186\n",
      " F1 Score (sklearn Unweighted): 0.3957347616922085\n",
      " F1 Score (sklearn Weighted): 0.5034056648838283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.2231\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2214\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2174\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2168\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2129\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2127\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2127\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2159\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2094\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2079\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2070\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2048\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2048\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2019\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2022\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2036\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2009\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1991\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1996\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1980\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1964\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1977\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1957\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1965\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1926\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1905\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1903\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1916\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1889\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1899\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1904\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1892\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1855\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1845\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1872\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1844\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1824\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1809\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1802\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1811\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1796\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1810\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1773\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1786\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1760\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1771\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1779\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1751\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1741\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1722\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1711\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1723\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1688\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1709\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1717\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1677\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1683\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1672\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1657\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1675\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1647\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1632\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1628\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1634\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1673\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1607\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1609\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1605\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1609\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1599\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1588\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1557\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1571\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1553\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1575\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1535\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1550\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1558\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1536\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1525\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1537\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1500\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1504\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1497\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1494\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1485\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1518\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1470\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1456\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1479\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1442\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1437\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1443\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1460\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1436\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1422\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1415\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1415\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1416\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1403\n",
      "18/18 [==============================] - 0s 911us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.08849557522123894\n",
      " Accuracy: 0.7646017699115044\n",
      " F1 Score (Weighted): 0.9013509414862919\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.7552044804816611\n",
      " F1 Score (sklearn Unweighted): 0.5610221992772328\n",
      " F1 Score (sklearn Weighted): 0.6151444656334397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1633\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1590\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1594\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1567\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1536\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1522\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1516\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1541\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1513\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1468\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1457\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1450\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1489\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1436\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1440\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1460\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1423\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1416\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1398\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1404\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1388\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1388\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1383\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1346\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1361\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1353\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1353\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1350\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1327\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1320\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1333\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1310\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1313\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1292\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1311\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1284\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1290\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1291\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1295\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1276\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1254\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1262\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1249\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1240\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1227\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1229\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1221\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1226\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1232\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1226\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1202\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1202\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1201\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1184\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1187\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1198\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1163\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1163\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1163\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1180\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1149\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1162\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1164\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1161\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1139\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1149\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1131\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1124\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1125\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1116\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1089\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1121\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1105\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1080\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1118\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1088\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1084\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1071\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1064\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1082\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1066\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1047\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1071\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1042\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1036\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1034\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1015\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1031\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1018\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1016\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1009\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1009\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1012\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1012\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0992\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1011\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1016\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1006\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0987\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0969\n",
      "18/18 [==============================] - 0s 720us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.08613569321533923\n",
      " Accuracy: 0.7734513274336283\n",
      " F1 Score (Weighted): 0.903953860499588\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.7688595249564675\n",
      " F1 Score (sklearn Unweighted): 0.5877805145046523\n",
      " F1 Score (sklearn Weighted): 0.6466806963239782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1338\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1295\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1288\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1254\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1222\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1216\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1227\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1206\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1190\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1170\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1183\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1161\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1147\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1147\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1131\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1157\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1121\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1132\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1139\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1129\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1101\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1123\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1129\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1103\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1087\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1069\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1075\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1078\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1055\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1058\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1071\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1080\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1048\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1046\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1028\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1038\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1036\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1020\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1065\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1002\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1031\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1007\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0982\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1008\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1007\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0994\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0969\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0983\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0979\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0973\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0962\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0964\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0954\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0963\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0951\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0952\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0922\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0944\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1011\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0945\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0931\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0916\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0935\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0901\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0912\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0910\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0898\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0901\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0892\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0887\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0887\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0881\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0876\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0875\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0869\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0915\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0887\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0887\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0856\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0847\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0865\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0842\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0841\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0834\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0835\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0841\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0815\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0842\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0828\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0829\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0810\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0803\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0830\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0796\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0786\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0803\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0781\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0786\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0797\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0781\n",
      "18/18 [==============================] - 0s 880us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.05309734513274336\n",
      " Accuracy: 0.8513274336283185\n",
      " F1 Score (Weighted): 0.943258154902156\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.8132096415843493\n",
      " F1 Score (sklearn Unweighted): 0.6562493189495479\n",
      " F1 Score (sklearn Weighted): 0.7286315036395906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0990\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0940\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0905\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0906\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0875\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0891\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0873\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0875\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0853\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0837\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0835\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0820\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0833\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0796\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0825\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0806\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0798\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0782\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0791\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0766\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0783\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0761\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0786\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0791\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0773\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0760\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0757\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0753\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0748\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0739\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0729\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0728\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0741\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0734\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0719\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0723\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0727\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0707\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0719\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0723\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0716\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0700\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0699\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0703\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0678\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0683\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0685\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0679\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0684\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0671\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0677\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0669\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0686\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0685\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0678\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0660\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0649\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0643\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0664\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0661\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0651\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0649\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0621\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0638\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0627\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0639\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0649\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0601\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0615\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0610\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0603\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0619\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0604\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0626\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0602\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0597\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0602\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0604\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0611\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0597\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0590\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0581\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0590\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0566\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0564\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0556\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0573\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0605\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0580\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0555\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0586\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0553\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0545\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0544\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0546\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0533\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0532\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.0525\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0561\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0601\n",
      "18/18 [==============================] - 0s 682us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.051418439716312055\n",
      " Accuracy: 0.8546099290780141\n",
      " F1 Score (Weighted): 0.9454934438149419\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.8525324676588175\n",
      " F1 Score (sklearn Unweighted): 0.7348790549079119\n",
      " F1 Score (sklearn Weighted): 0.7831331944942592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8865277054527382,\n",
       " 0.9013509414862919,\n",
       " 0.903953860499588,\n",
       " 0.943258154902156,\n",
       " 0.9454934438149419]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim  = len(train_x.columns)\n",
    "output_dim = len(train_y.columns)\n",
    "model = BaseBacModel(input_dim, output_dim, 512)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "cross_train(train_x, train_y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 640us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.10985384252710985\n",
      " Accuracy: 0.7199434229137199\n",
      " F1 Score (Weighted): 0.8768480826575886\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.6780018339784029\n",
      " F1 Score (sklearn Unweighted): 0.41973046477353876\n",
      " F1 Score (sklearn Weighted): 0.4921601590821736\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_x)\n",
    "pred_binary = pred.round()\n",
    "\n",
    "hl, acc, f1w = report(test_y, pred_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    \n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    \n",
    "    input_dim  = len(train_x.columns)\n",
    "    output_dim = len(train_y.columns)\n",
    "    \n",
    "    model = BaseBacModel(input_dim, output_dim, hp_units)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    model_builder,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 300 Complete [00h 00m 04s]\n",
      "val_loss: 0.310035765171051\n",
      "\n",
      "Best val_loss So Far: 0.3031507134437561\n",
      "Total elapsed time: 00h 26m 51s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 160 and the optimal learning rate for the optimizer\n",
      "is 0.01.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_x, train_y, epochs=150, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "71/71 [==============================] - 1s 3ms/step - loss: 0.4000 - val_loss: 0.3550\n",
      "Epoch 2/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3523 - val_loss: 0.3442\n",
      "Epoch 3/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.3331\n",
      "Epoch 4/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3251 - val_loss: 0.3277\n",
      "Epoch 5/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3174 - val_loss: 0.3288\n",
      "Epoch 6/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3161 - val_loss: 0.3244\n",
      "Epoch 7/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.3072 - val_loss: 0.3427\n",
      "Epoch 8/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.3042 - val_loss: 0.3302\n",
      "Epoch 9/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3042 - val_loss: 0.3222\n",
      "Epoch 10/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2972 - val_loss: 0.3199\n",
      "Epoch 11/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2957 - val_loss: 0.3137\n",
      "Epoch 12/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2901 - val_loss: 0.3124\n",
      "Epoch 13/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2874 - val_loss: 0.3164\n",
      "Epoch 14/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2904 - val_loss: 0.3404\n",
      "Epoch 15/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2905 - val_loss: 0.3185\n",
      "Epoch 16/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2789 - val_loss: 0.3114\n",
      "Epoch 17/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2765 - val_loss: 0.3285\n",
      "Epoch 18/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2705 - val_loss: 0.3091\n",
      "Epoch 19/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.2738 - val_loss: 0.3174\n",
      "Epoch 20/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.2665 - val_loss: 0.3190\n",
      "Epoch 21/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2679 - val_loss: 0.3165\n",
      "Epoch 22/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2626 - val_loss: 0.3106\n",
      "Epoch 23/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2580 - val_loss: 0.3153\n",
      "Epoch 24/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.2560 - val_loss: 0.3157\n",
      "Epoch 25/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.2532 - val_loss: 0.3198\n",
      "Epoch 26/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.2541 - val_loss: 0.3266\n",
      "Epoch 27/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.2524 - val_loss: 0.3193\n",
      "Epoch 28/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.2489 - val_loss: 0.3092\n",
      "Epoch 29/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2453 - val_loss: 0.3190\n",
      "Epoch 30/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.2427 - val_loss: 0.3271\n",
      "Epoch 31/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2417 - val_loss: 0.3237\n",
      "Epoch 32/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2395 - val_loss: 0.3418\n",
      "Epoch 33/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2383 - val_loss: 0.3216\n",
      "Epoch 34/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2284 - val_loss: 0.3185\n",
      "Epoch 35/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2295 - val_loss: 0.3114\n",
      "Epoch 36/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2310 - val_loss: 0.3138\n",
      "Epoch 37/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2249 - val_loss: 0.3297\n",
      "Epoch 38/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2270 - val_loss: 0.3263\n",
      "Epoch 39/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2260 - val_loss: 0.3281\n",
      "Epoch 40/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2187 - val_loss: 0.3253\n",
      "Epoch 41/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2182 - val_loss: 0.3258\n",
      "Epoch 42/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.2139 - val_loss: 0.3360\n",
      "Epoch 43/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2167 - val_loss: 0.3342\n",
      "Epoch 44/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2173 - val_loss: 0.3374\n",
      "Epoch 45/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2064 - val_loss: 0.3344\n",
      "Epoch 46/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2129 - val_loss: 0.3284\n",
      "Epoch 47/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2074 - val_loss: 0.3383\n",
      "Epoch 48/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2076 - val_loss: 0.3517\n",
      "Epoch 49/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2011 - val_loss: 0.3352\n",
      "Epoch 50/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.3428\n",
      "Epoch 51/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1990 - val_loss: 0.3439\n",
      "Epoch 52/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1951 - val_loss: 0.3561\n",
      "Epoch 53/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1932 - val_loss: 0.3577\n",
      "Epoch 54/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1911 - val_loss: 0.3370\n",
      "Epoch 55/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1900 - val_loss: 0.3553\n",
      "Epoch 56/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1880 - val_loss: 0.3506\n",
      "Epoch 57/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1842 - val_loss: 0.3489\n",
      "Epoch 58/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1831 - val_loss: 0.3587\n",
      "Epoch 59/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1829 - val_loss: 0.3718\n",
      "Epoch 60/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1792 - val_loss: 0.3520\n",
      "Epoch 61/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1839 - val_loss: 0.3675\n",
      "Epoch 62/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1830 - val_loss: 0.3581\n",
      "Epoch 63/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1752 - val_loss: 0.3663\n",
      "Epoch 64/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1769 - val_loss: 0.3480\n",
      "Epoch 65/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.3480\n",
      "Epoch 66/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1692 - val_loss: 0.3875\n",
      "Epoch 67/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1654 - val_loss: 0.3788\n",
      "Epoch 68/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1672 - val_loss: 0.3650\n",
      "Epoch 69/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1649 - val_loss: 0.3777\n",
      "Epoch 70/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1675 - val_loss: 0.3628\n",
      "Epoch 71/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1609 - val_loss: 0.3836\n",
      "Epoch 72/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1605 - val_loss: 0.3815\n",
      "Epoch 73/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1615 - val_loss: 0.3842\n",
      "Epoch 74/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1658 - val_loss: 0.3956\n",
      "Epoch 75/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1693 - val_loss: 0.4054\n",
      "Epoch 76/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1593 - val_loss: 0.3887\n",
      "Epoch 77/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1537 - val_loss: 0.3773\n",
      "Epoch 78/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1478 - val_loss: 0.3807\n",
      "Epoch 79/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1524 - val_loss: 0.4118\n",
      "Epoch 80/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1531 - val_loss: 0.3958\n",
      "Epoch 81/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1467 - val_loss: 0.3822\n",
      "Epoch 82/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1494 - val_loss: 0.3867\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.4062\n",
      "Epoch 84/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1450 - val_loss: 0.3963\n",
      "Epoch 85/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1467 - val_loss: 0.4104\n",
      "Epoch 86/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1424 - val_loss: 0.4148\n",
      "Epoch 87/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1428 - val_loss: 0.4089\n",
      "Epoch 88/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1389 - val_loss: 0.4073\n",
      "Epoch 89/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1372 - val_loss: 0.4200\n",
      "Epoch 90/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1374 - val_loss: 0.4288\n",
      "Epoch 91/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1346 - val_loss: 0.4173\n",
      "Epoch 92/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1354 - val_loss: 0.4258\n",
      "Epoch 93/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1357 - val_loss: 0.4371\n",
      "Epoch 94/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1338 - val_loss: 0.4344\n",
      "Epoch 95/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1266 - val_loss: 0.4176\n",
      "Epoch 96/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1262 - val_loss: 0.4457\n",
      "Epoch 97/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1271 - val_loss: 0.4269\n",
      "Epoch 98/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1243 - val_loss: 0.4355\n",
      "Epoch 99/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1257 - val_loss: 0.4393\n",
      "Epoch 100/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1227 - val_loss: 0.4546\n",
      "Epoch 101/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1280 - val_loss: 0.4682\n",
      "Epoch 102/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.4741\n",
      "Epoch 103/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1250 - val_loss: 0.4595\n",
      "Epoch 104/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1203 - val_loss: 0.4471\n",
      "Epoch 105/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1198 - val_loss: 0.4573\n",
      "Epoch 106/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1222 - val_loss: 0.4676\n",
      "Epoch 107/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1161 - val_loss: 0.4584\n",
      "Epoch 108/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1157 - val_loss: 0.4514\n",
      "Epoch 109/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.4784\n",
      "Epoch 110/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1145 - val_loss: 0.4647\n",
      "Epoch 111/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1180 - val_loss: 0.4913\n",
      "Epoch 112/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.4979\n",
      "Epoch 113/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.4895\n",
      "Epoch 114/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1136 - val_loss: 0.4939\n",
      "Epoch 115/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1160 - val_loss: 0.4858\n",
      "Epoch 116/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.4823\n",
      "Epoch 117/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.4805\n",
      "Epoch 118/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1112 - val_loss: 0.5150\n",
      "Epoch 119/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1132 - val_loss: 0.4940\n",
      "Epoch 120/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.5169\n",
      "Epoch 121/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1099 - val_loss: 0.4907\n",
      "Epoch 122/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1024 - val_loss: 0.4892\n",
      "Epoch 123/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1003 - val_loss: 0.4892\n",
      "Epoch 124/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1057 - val_loss: 0.4966\n",
      "Epoch 125/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1016 - val_loss: 0.5017\n",
      "Epoch 126/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0988 - val_loss: 0.5370\n",
      "Epoch 127/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0955 - val_loss: 0.5178\n",
      "Epoch 128/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0964 - val_loss: 0.5159\n",
      "Epoch 129/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1032 - val_loss: 0.5422\n",
      "Epoch 130/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1024 - val_loss: 0.5247\n",
      "Epoch 131/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1021 - val_loss: 0.5277\n",
      "Epoch 132/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0970 - val_loss: 0.5317\n",
      "Epoch 133/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0936 - val_loss: 0.5534\n",
      "Epoch 134/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0952 - val_loss: 0.5425\n",
      "Epoch 135/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0942 - val_loss: 0.5542\n",
      "Epoch 136/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0874 - val_loss: 0.5463\n",
      "Epoch 137/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.5242\n",
      "Epoch 138/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0902 - val_loss: 0.5303\n",
      "Epoch 139/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0892 - val_loss: 0.5372\n",
      "Epoch 140/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1024 - val_loss: 0.5703\n",
      "Epoch 141/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0931 - val_loss: 0.5431\n",
      "Epoch 142/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.5683\n",
      "Epoch 143/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.5794\n",
      "Epoch 144/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.5721\n",
      "Epoch 145/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.5853\n",
      "Epoch 146/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0849 - val_loss: 0.5968\n",
      "Epoch 147/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.5906\n",
      "Epoch 148/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.5857\n",
      "Epoch 149/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.6176\n",
      "Epoch 150/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.5953\n",
      "Best epoch: 149\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(train_x, train_y, epochs=150, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history[\"val_loss\"]\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.4014\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.3492\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.3343\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.3218\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3269\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3103\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3090\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3013\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2982\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2976\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2912\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2881\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2875\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2835\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2841\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2780\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2780\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2758\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2695\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2678\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2674\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2662\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2601\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2598\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2565\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2549\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2531\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2514\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2517\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2427\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2447\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2400\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2423\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2373\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2328\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2283\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.2350\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.2290\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2234\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2273\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2269\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2212\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2176\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2168\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2098\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2148\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2067\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2060\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2019\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2035\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2014\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2059\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2020\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1970\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1947\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1889\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1967\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1898\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1863\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1866\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1870\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1870\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1808\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1817\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1750\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1737\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1756\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1709\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1718\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1757\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1701\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1638\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1709\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1654\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1603\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1586\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1585\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1572\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1560\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1544\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1614\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1530\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1580\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1468\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1413\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1439\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1462\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1432\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1457\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1421\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1354\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1362\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1429\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1396\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1360\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1363\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1367\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1387\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1294\n",
      "18/18 [==============================] - 0s 617us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.10973451327433628\n",
      " Accuracy: 0.7008849557522124\n",
      " F1 Score (Weighted): 0.8797605319726202\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.6728740358029514\n",
      " F1 Score (sklearn Unweighted): 0.408378994507603\n",
      " F1 Score (sklearn Weighted): 0.5061276028305007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 934us/step - loss: 0.2096\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.2047\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1909\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1880\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1785\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1776\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1754\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1649\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1637\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1596\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1610\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1519\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1519\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1542\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1522\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1553\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1503\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1475\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1438\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1462\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1369\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1411\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1374\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1376\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1317\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1301\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1290\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1311\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1274\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1285\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1281\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1301\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1190\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1169\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1212\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1179\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1212\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1189\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1232\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1141\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1158\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1104\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1176\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1105\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1105\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1159\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1097\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1033\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1094\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1075\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1038\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1048\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0988\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0998\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0986\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0996\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1017\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0966\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0957\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1035\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1012\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1005\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0955\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0963\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0975\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0889\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0878\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0911\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0977\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0932\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0830\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0810\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0854\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0839\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0851\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0862\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0883\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0868\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0794\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0854\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0800\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0739\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0758\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0769\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0801\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0760\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0766\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0760\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0679\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0696\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0664\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0649\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0709\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0832\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0710\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0693\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0711\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0708\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0797\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0675\n",
      "18/18 [==============================] - 0s 726us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.09026548672566372\n",
      " Accuracy: 0.7575221238938054\n",
      " F1 Score (Weighted): 0.8996186260641709\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.7649269829001012\n",
      " F1 Score (sklearn Unweighted): 0.5815205403915081\n",
      " F1 Score (sklearn Weighted): 0.608091018044935\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 932us/step - loss: 0.1946\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1837\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1399\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1324\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1177\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1083\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0995\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1000\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0972\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1135\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0944\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0876\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0929\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0886\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0977\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1029\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0847\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0815\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0794\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0795\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0796\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0825\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1116\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0838\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0795\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0820\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0798\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0800\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0717\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0700\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0757\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0748\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0691\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0650\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0644\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0712\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0635\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0627\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0671\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0633\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0652\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0638\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0666\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0634\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1262\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0876\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0656\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0595\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0653\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0590\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0608\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0560\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0549\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0568\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0627\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0682\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0613\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0558\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0500\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0536\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0505\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0531\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0563\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0574\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0612\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0509\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0484\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0530\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0532\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0505\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0489\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0470\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0471\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0479\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0442\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0509\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0671\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0560\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0489\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0460\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0430\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0443\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0607\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0563\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0457\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0413\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0469\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0382\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0374\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0354\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0385\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0605\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0511\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0387\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0379\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0361\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0394\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0502\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0379\n",
      "18/18 [==============================] - 0s 613us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.08790560471976401\n",
      " Accuracy: 0.7663716814159292\n",
      " F1 Score (Weighted): 0.9095103528715557\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.8053484862001034\n",
      " F1 Score (sklearn Unweighted): 0.6633001028854736\n",
      " F1 Score (sklearn Weighted): 0.695755693666782\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 940us/step - loss: 0.1470\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1726\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1287\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0935\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0734\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0701\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0796\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0761\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0663\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0637\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0716\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0593\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0601\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0606\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0667\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0635\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0525\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0532\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0538\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0719\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0674\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0588\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0559\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0619\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0518\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0578\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0501\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0446\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0441\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0471\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0471\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0513\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0466\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0454\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0428\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0439\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0499\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0529\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0512\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0627\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0646\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0512\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0393\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0381\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0434\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0418\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0497\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0385\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0361\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0417\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0435\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0362\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0335\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0427\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0439\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0390\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0340\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0358\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0371\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0347\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0408\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0408\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0458\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0447\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0805\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0706\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0617\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0450\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0359\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0348\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0324\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0316\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0284\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0302\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0270\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0311\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0271\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0290\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0260\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0247\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0263\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0292\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0358\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0327\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0262\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0267\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0255\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0291\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0345\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0314\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0280\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0249\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0257\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0269\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0672\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0638\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0563\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0502\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0273\n",
      "18/18 [==============================] - 0s 759us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.049557522123893805\n",
      " Accuracy: 0.8601769911504424\n",
      " F1 Score (Weighted): 0.9522495197575852\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.8622324808798832\n",
      " F1 Score (sklearn Unweighted): 0.7528572568055698\n",
      " F1 Score (sklearn Weighted): 0.797985367948121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1312\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.1127\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0702\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0554\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0471\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0456\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0563\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0424\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0394\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0331\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0335\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0458\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0365\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0305\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0340\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0345\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0378\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0332\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0288\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0262\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0296\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0325\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0566\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0409\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0442\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0524\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0312\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0292\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0298\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0282\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0237\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0220\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0313\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0272\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0357\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0465\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0819\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0600\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0428\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0300\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0236\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0206\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0256\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0258\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0193\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0199\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0189\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0187\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0192\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0243\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0237\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0256\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0269\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0241\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0283\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0264\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0212\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0231\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0192\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0236\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0260\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0280\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0277\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0407\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0377\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0413\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0318\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0318\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0710\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0326\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0183\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0139\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0127\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0415\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0510\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0435\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0536\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0219\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0129\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0135\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0136\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0113\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0125\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0117\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0111\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0590\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.0651\n",
      "18/18 [==============================] - 0s 599us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.04905437352245863\n",
      " Accuracy: 0.8599290780141844\n",
      " F1 Score (Weighted): 0.9484634977795269\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.8544858610281576\n",
      " F1 Score (sklearn Unweighted): 0.7374318116566179\n",
      " F1 Score (sklearn Weighted): 0.7970188429388306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8797605319726202,\n",
       " 0.8996186260641709,\n",
       " 0.9095103528715557,\n",
       " 0.9522495197575852,\n",
       " 0.9484634977795269]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "cross_train(train_x, train_y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 644us/step\n",
      "Main metrics:\n",
      " Hamming Loss: 0.132013201320132\n",
      " Accuracy: 0.6633663366336634\n",
      " F1 Score (Weighted): 0.8636790739870047\n",
      "================================================\n",
      "Other metrics:\n",
      " F1 Score (Unweighted): 0.6683956836802952\n",
      " F1 Score (sklearn Unweighted): 0.41447337221985103\n",
      " F1 Score (sklearn Weighted): 0.4829331839362714\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_x)\n",
    "pred_binary = pred.round()\n",
    "\n",
    "hl, acc, f1w = report(test_y, pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
