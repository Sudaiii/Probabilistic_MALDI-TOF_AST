{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "antibiotic_dictionary_file = open(\"data/antibiotics.json\", \"r\")\n",
    "antibiotic_dictionary = json.load(antibiotic_dictionary_file)\n",
    "antibiotics = antibiotic_dictionary[\"Escherichia coli\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>...</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>Ciprofloxacin</th>\n",
       "      <th>Ceftriaxone</th>\n",
       "      <th>Piperacillin-Tazobactam</th>\n",
       "      <th>Cefepime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012174</td>\n",
       "      <td>0.013379</td>\n",
       "      <td>0.013813</td>\n",
       "      <td>0.019293</td>\n",
       "      <td>0.019271</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012835</td>\n",
       "      <td>0.015030</td>\n",
       "      <td>0.016545</td>\n",
       "      <td>0.019867</td>\n",
       "      <td>0.021450</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.016463</td>\n",
       "      <td>0.012731</td>\n",
       "      <td>0.012761</td>\n",
       "      <td>0.013359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022339</td>\n",
       "      <td>0.024486</td>\n",
       "      <td>0.018417</td>\n",
       "      <td>0.022405</td>\n",
       "      <td>0.024961</td>\n",
       "      <td>0.029598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036591</td>\n",
       "      <td>0.038338</td>\n",
       "      <td>0.040873</td>\n",
       "      <td>0.047490</td>\n",
       "      <td>0.052187</td>\n",
       "      <td>0.055778</td>\n",
       "      <td>0.055738</td>\n",
       "      <td>0.047467</td>\n",
       "      <td>0.046334</td>\n",
       "      <td>0.045266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080196</td>\n",
       "      <td>0.091884</td>\n",
       "      <td>0.095694</td>\n",
       "      <td>0.081280</td>\n",
       "      <td>0.082773</td>\n",
       "      <td>0.095949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017140</td>\n",
       "      <td>0.017536</td>\n",
       "      <td>0.018672</td>\n",
       "      <td>0.018508</td>\n",
       "      <td>0.017872</td>\n",
       "      <td>0.019658</td>\n",
       "      <td>0.020053</td>\n",
       "      <td>0.020572</td>\n",
       "      <td>0.018712</td>\n",
       "      <td>0.018686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025351</td>\n",
       "      <td>0.026505</td>\n",
       "      <td>0.024017</td>\n",
       "      <td>0.024147</td>\n",
       "      <td>0.030135</td>\n",
       "      <td>0.025802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.004182</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041165</td>\n",
       "      <td>0.043797</td>\n",
       "      <td>0.061598</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.049534</td>\n",
       "      <td>0.073161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>0.017158</td>\n",
       "      <td>0.018512</td>\n",
       "      <td>0.018706</td>\n",
       "      <td>0.020291</td>\n",
       "      <td>0.020911</td>\n",
       "      <td>0.020753</td>\n",
       "      <td>0.019474</td>\n",
       "      <td>0.018620</td>\n",
       "      <td>0.018705</td>\n",
       "      <td>0.018179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053464</td>\n",
       "      <td>0.057933</td>\n",
       "      <td>0.055251</td>\n",
       "      <td>0.051033</td>\n",
       "      <td>0.054449</td>\n",
       "      <td>0.082976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>0.024098</td>\n",
       "      <td>0.023388</td>\n",
       "      <td>0.023772</td>\n",
       "      <td>0.025077</td>\n",
       "      <td>0.024409</td>\n",
       "      <td>0.024004</td>\n",
       "      <td>0.026094</td>\n",
       "      <td>0.027139</td>\n",
       "      <td>0.027487</td>\n",
       "      <td>0.023848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019453</td>\n",
       "      <td>0.022214</td>\n",
       "      <td>0.023768</td>\n",
       "      <td>0.017426</td>\n",
       "      <td>0.018883</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>0.010605</td>\n",
       "      <td>0.013530</td>\n",
       "      <td>0.013734</td>\n",
       "      <td>0.014226</td>\n",
       "      <td>0.014336</td>\n",
       "      <td>0.014168</td>\n",
       "      <td>0.013768</td>\n",
       "      <td>0.012725</td>\n",
       "      <td>0.010554</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>0.006595</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3689</th>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.008374</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.008565</td>\n",
       "      <td>0.008374</td>\n",
       "      <td>0.007656</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>0.009450</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017319</td>\n",
       "      <td>0.016282</td>\n",
       "      <td>0.018666</td>\n",
       "      <td>0.019666</td>\n",
       "      <td>0.018883</td>\n",
       "      <td>0.029474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>0.016356</td>\n",
       "      <td>0.013185</td>\n",
       "      <td>0.014376</td>\n",
       "      <td>0.014433</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>0.013317</td>\n",
       "      <td>0.013925</td>\n",
       "      <td>0.015426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033886</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>0.033848</td>\n",
       "      <td>0.026761</td>\n",
       "      <td>0.030264</td>\n",
       "      <td>0.027448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3691 rows × 8004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          2000      2001      2002      2003      2004      2005      2006   \n",
       "0     0.001530  0.001362  0.001367  0.001134  0.001164  0.000875  0.001573  \\\n",
       "1     0.012835  0.015030  0.016545  0.019867  0.021450  0.018100  0.016463   \n",
       "2     0.036591  0.038338  0.040873  0.047490  0.052187  0.055778  0.055738   \n",
       "3     0.017140  0.017536  0.018672  0.018508  0.017872  0.019658  0.020053   \n",
       "4     0.003033  0.003481  0.002779  0.004176  0.004205  0.002828  0.004182   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3686  0.017158  0.018512  0.018706  0.020291  0.020911  0.020753  0.019474   \n",
       "3687  0.024098  0.023388  0.023772  0.025077  0.024409  0.024004  0.026094   \n",
       "3688  0.010605  0.013530  0.013734  0.014226  0.014336  0.014168  0.013768   \n",
       "3689  0.007466  0.008374  0.008350  0.008565  0.008374  0.007656  0.008862   \n",
       "3690  0.016356  0.013185  0.014376  0.014433  0.014408  0.011501  0.012288   \n",
       "\n",
       "          2007      2008      2009  ...      9994      9995      9996   \n",
       "0     0.000936  0.001014  0.001009  ...  0.012174  0.013379  0.013813  \\\n",
       "1     0.012731  0.012761  0.013359  ...  0.022339  0.024486  0.018417   \n",
       "2     0.047467  0.046334  0.045266  ...  0.080196  0.091884  0.095694   \n",
       "3     0.020572  0.018712  0.018686  ...  0.025351  0.026505  0.024017   \n",
       "4     0.003030  0.002802  0.003335  ...  0.041165  0.043797  0.061598   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3686  0.018620  0.018705  0.018179  ...  0.053464  0.057933  0.055251   \n",
       "3687  0.027139  0.027487  0.023848  ...  0.019453  0.022214  0.023768   \n",
       "3688  0.012725  0.010554  0.012690  ...  0.003765  0.008078  0.006595   \n",
       "3689  0.009450  0.010870  0.010106  ...  0.017319  0.016282  0.018666   \n",
       "3690  0.013317  0.013925  0.015426  ...  0.033886  0.035971  0.033848   \n",
       "\n",
       "          9997      9998      9999  Ciprofloxacin  Ceftriaxone   \n",
       "0     0.019293  0.019271  0.010970            0.0          0.0  \\\n",
       "1     0.022405  0.024961  0.029598            1.0          1.0   \n",
       "2     0.081280  0.082773  0.095949            0.0          1.0   \n",
       "3     0.024147  0.030135  0.025802            0.0          0.0   \n",
       "4     0.038835  0.049534  0.073161            0.0          0.0   \n",
       "...        ...       ...       ...            ...          ...   \n",
       "3686  0.051033  0.054449  0.082976            0.0          0.0   \n",
       "3687  0.017426  0.018883  0.009809            1.0          1.0   \n",
       "3688  0.004730  0.002975  0.003650            0.0          0.0   \n",
       "3689  0.019666  0.018883  0.029474            0.0          0.0   \n",
       "3690  0.026761  0.030264  0.027448            1.0          1.0   \n",
       "\n",
       "      Piperacillin-Tazobactam  Cefepime  \n",
       "0                         0.0       0.0  \n",
       "1                         0.0       1.0  \n",
       "2                         0.0       1.0  \n",
       "3                         0.0       0.0  \n",
       "4                         1.0       0.0  \n",
       "...                       ...       ...  \n",
       "3686                      0.0       0.0  \n",
       "3687                      0.0       1.0  \n",
       "3688                      1.0       0.0  \n",
       "3689                      0.0       0.0  \n",
       "3690                      0.0       0.0  \n",
       "\n",
       "[3691 rows x 8004 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"data/processed/raw/train_e_coli_driams.csv\"\n",
    "\n",
    "train_bac = pd.read_csv(file)\n",
    "train_bac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_bac[train_bac.columns.drop(list(train_bac.filter(regex='[^0-9]')))]\n",
    "y_train = train_bac[antibiotics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Fitting estimator with 2000 features.\n",
      "Fitting estimator with 1900 features.\n",
      "Fitting estimator with 1800 features.\n",
      "Fitting estimator with 1700 features.\n",
      "Fitting estimator with 1600 features.\n",
      "Fitting estimator with 1500 features.\n",
      "Fitting estimator with 1400 features.\n",
      "Fitting estimator with 1300 features.\n",
      "Fitting estimator with 1200 features.\n",
      "Fitting estimator with 1100 features.\n",
      "Fitting estimator with 1000 features.\n",
      "Fitting estimator with 900 features.\n",
      "Fitting estimator with 800 features.\n",
      "Fitting estimator with 700 features.\n",
      "Fitting estimator with 600 features.\n",
      "Fitting estimator with 500 features.\n",
      "Fitting estimator with 400 features.\n",
      "Fitting estimator with 300 features.\n",
      "Fitting estimator with 200 features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                            colsample_bylevel=None, colsample_bynode=None,\n",
       "                            colsample_bytree=None, early_stopping_rounds=None,\n",
       "                            enable_categorical=False, eval_metric=None,\n",
       "                            feature_types=None, gamma=None, gpu_id=None,\n",
       "                            grow_policy=None, importance_type=None,\n",
       "                            interaction_constraints=None, learning_rate=None,\n",
       "                            max_bin=None, max_cat_threshold=None,\n",
       "                            max_cat_to_onehot=None, max_delta_step=None,\n",
       "                            max_depth=None, max_leaves=None,\n",
       "                            min_child_weight=None, missing=nan,\n",
       "                            monotone_constraints=None, n_estimators=100,\n",
       "                            n_jobs=None, num_parallel_tree=None, predictor=None,\n",
       "                            random_state=None, ...),\n",
       "    n_features_to_select=100, step=100, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                            colsample_bylevel=None, colsample_bynode=None,\n",
       "                            colsample_bytree=None, early_stopping_rounds=None,\n",
       "                            enable_categorical=False, eval_metric=None,\n",
       "                            feature_types=None, gamma=None, gpu_id=None,\n",
       "                            grow_policy=None, importance_type=None,\n",
       "                            interaction_constraints=None, learning_rate=None,\n",
       "                            max_bin=None, max_cat_threshold=None,\n",
       "                            max_cat_to_onehot=None, max_delta_step=None,\n",
       "                            max_depth=None, max_leaves=None,\n",
       "                            min_child_weight=None, missing=nan,\n",
       "                            monotone_constraints=None, n_estimators=100,\n",
       "                            n_jobs=None, num_parallel_tree=None, predictor=None,\n",
       "                            random_state=None, ...),\n",
       "    n_features_to_select=100, step=100, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                            colsample_bylevel=None, colsample_bynode=None,\n",
       "                            colsample_bytree=None, early_stopping_rounds=None,\n",
       "                            enable_categorical=False, eval_metric=None,\n",
       "                            feature_types=None, gamma=None, gpu_id=None,\n",
       "                            grow_policy=None, importance_type=None,\n",
       "                            interaction_constraints=None, learning_rate=None,\n",
       "                            max_bin=None, max_cat_threshold=None,\n",
       "                            max_cat_to_onehot=None, max_delta_step=None,\n",
       "                            max_depth=None, max_leaves=None,\n",
       "                            min_child_weight=None, missing=nan,\n",
       "                            monotone_constraints=None, n_estimators=100,\n",
       "                            n_jobs=None, num_parallel_tree=None, predictor=None,\n",
       "                            random_state=None, ...),\n",
       "    n_features_to_select=100, step=100, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = RFE(\n",
    "    estimator=xgb.XGBClassifier(objective=\"binary:logistic\"),\n",
    "    n_features_to_select=100,\n",
    "    step=100,\n",
    "    verbose=1\n",
    ")\n",
    "selector.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = selector.support_\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008',\n",
       "       '2009',\n",
       "       ...\n",
       "       '9990', '9991', '9992', '9993', '9994', '9995', '9996', '9997', '9998',\n",
       "       '9999'],\n",
       "      dtype='object', length=8000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = x_train.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2013',\n",
       " '2021',\n",
       " '2065',\n",
       " '2066',\n",
       " '2067',\n",
       " '2073',\n",
       " '2087',\n",
       " '2136',\n",
       " '2137',\n",
       " '2138',\n",
       " '2150',\n",
       " '2151',\n",
       " '2152',\n",
       " '2153',\n",
       " '2154',\n",
       " '2243',\n",
       " '2245',\n",
       " '2297',\n",
       " '2536',\n",
       " '2592',\n",
       " '2631',\n",
       " '2632',\n",
       " '2633',\n",
       " '2798',\n",
       " '2833',\n",
       " '2903',\n",
       " '2983',\n",
       " '3103',\n",
       " '3104',\n",
       " '3137',\n",
       " '3140',\n",
       " '3365',\n",
       " '3400',\n",
       " '3404',\n",
       " '3405',\n",
       " '3441',\n",
       " '3501',\n",
       " '3535',\n",
       " '3731',\n",
       " '3881',\n",
       " '4036',\n",
       " '4129',\n",
       " '4661',\n",
       " '5021',\n",
       " '5237',\n",
       " '5241',\n",
       " '5290',\n",
       " '5297',\n",
       " '5591',\n",
       " '5599',\n",
       " '5669',\n",
       " '5682',\n",
       " '5736',\n",
       " '5753',\n",
       " '5798',\n",
       " '5853',\n",
       " '5857',\n",
       " '5858',\n",
       " '5859',\n",
       " '5862',\n",
       " '5889',\n",
       " '5890',\n",
       " '5891',\n",
       " '5892',\n",
       " '5893',\n",
       " '5895',\n",
       " '5896',\n",
       " '5897',\n",
       " '5898',\n",
       " '6165',\n",
       " '6459',\n",
       " '6551',\n",
       " '6552',\n",
       " '6640',\n",
       " '6805',\n",
       " '6807',\n",
       " '6808',\n",
       " '6809',\n",
       " '6810',\n",
       " '6862',\n",
       " '6863',\n",
       " '6865',\n",
       " '6866',\n",
       " '6867',\n",
       " '6868',\n",
       " '6869',\n",
       " '6900',\n",
       " '6901',\n",
       " '6902',\n",
       " '6906',\n",
       " '7333',\n",
       " '7365',\n",
       " '7384',\n",
       " '7412',\n",
       " '7423',\n",
       " '7426',\n",
       " '7654',\n",
       " '8448',\n",
       " '8451',\n",
       " '8507']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = []\n",
    "for i in range(columns.size):\n",
    "    if mask[i] == True:\n",
    "        selected_features.append(columns[i])\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_ext = os.path.basename(file)\n",
    "file_name = os.path.splitext(file_name_ext)[0]\n",
    "file_name_cleaned = file_name.replace(\"train_\", \"\") \n",
    "feature_file_address = \"data/features/\"+file_name_cleaned+\"_selected_features.txt\"\n",
    "feature_file = open(feature_file_address, \"w\")\n",
    "for feature in selected_features:\n",
    "    feature_file.write(feature+\",\")\n",
    "feature_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
